# Meltdown与Spectre

# 1. 写在最前面
今年一月份，几位同学在讨论那段时间被炒得沸沸扬扬的Meltdown [[43]] 与Spectre 
[[44]]系统漏洞，于是凑热闹翻阅了包括Google的那两篇论文在内的一些资料，又因为自己
的习惯，忍不住写了这样一篇东西，算是给自己备个忘，也算对自己的时间有个交代吧。因
为平时比较忙，所以只能利用一些时间碎片零敲碎打地写写，于是一直拖到现在才完成。毕
竟不算是严肃的论文，加上时间有限，所以难免有各种错误，请见谅。如果你发现任何错误
，欢迎反馈给我，我会在有空的时候更新文档。

如果要把这两个问题讲明白，需要了解很多系统架构与系统安全方面的知识，因此本文会首
先介绍一些基本知识。为了能让更多读者理解，我会尽量用容易理解的语言来介绍这些知识
，但即便如此，本文所涉及的内容也十分庞杂，因此如果你是位心急的读者，只想通过一两
句话了解这两个安全漏洞大概的原理，那么网络上有很多速成的扫盲贴，本文并不适合你。

注：因为缺乏必要的知识储备，我们此处暂不分析Meltdown与Spectre的技术细节，而首先
关注这两个系统漏洞的危害、影响范围、以及应对措施。

在写这份报告的过程中，通过阅读相关的资料，我对系统架构与安全的理解比之前更深入了
一层，从这个角度而言，自己的时间也算没有浪费。

## 1.1 Meltdown / 熔毁
* 危害：Meltdown漏洞允许攻击者程序读取整个内核内存空间的内容；

* 影响范围：目前Meltdown只在Intel的CPU上成功重现（但不能排除影响其它CPU的可能性
  ）；

* 应对措施：目前最有效的方法就是在操作系统中启用KAISER [[61]]；

* 如何评价：Meltdown是由CPU的设计缺陷造成的；

* 原理：暂不讨论

## 1.2 Spectre / 幽灵
* 危害：Spectre漏洞允许攻击者“欺骗”被攻击程序执行错误的代码来泄露自己的敏感信息
  ；

* 影响范围：由Intel、AMD、以及ARM生产的CPU；

* 应对措施: 目前除了修改以及重新编译可能被攻击的软件，暂时没有有效的系统级解决方
  案；

* 如何评价：部分研究者认为，本质上Spectre的根源并不是CPU的设计缺陷 [[4]]，因为现
  代计算机中硬件与软件的协同工作方式已经这样存在了很多年，并且是基于公开的计算机
  理论。换句话说，如果一定要归咎于某种缺陷，那么也应该算是计算机理论的缺陷。因此
  ，据说Spectre漏洞的发现者是通过阅读CPU技术手册而推断出漏洞的，也就非常合理了，
  因为所有的设计都是基于被广泛认可的公开的理论与标准。

  此外，各种边信道攻击方式 / side-channel attacks （例如根据内存与缓存读取速度的
  差别来发动攻击，根据网络响应速度快慢来发动攻击，根据耗电量的多少来发动攻击，等
  等）也已经存在了很多年 [[47]] [[48]] [[49]] [[50]] [[51]]。并且从本质上而言，
  硬件厂商对这一类攻击也并没有一劳永逸的解决方案，因为这类攻击同样也是基于公开的
  现代计算机的体系结构，我们因此也不能说这就是硬件的设计缺陷所致。

  事实上，抛开Spectre不谈，即便在此时此刻，我们也并不能完全确定硬件厂商已经对我
  们正在使用的计算机提供了足够的保护，从而让我们可以对以往所有类型的攻击免疫，因
  为只要稍微研究一下以往的攻击手段，你就会绝望地发现，对于某些攻击，至少在相当长
  的一段时期内，硬件厂商其实是无能为力的。然而，即便现实已经如此残酷，大部分人似
  乎对此并没有表现出本应该有的那种紧张，那么为什么这一次的Spectre却彷佛在一夜之
  间引起了轩然大波呢？我认为原因有两个：1) Spectre的攻击策略更出人意料，比以往的
  攻击方式更有想象力；2) 媒体的大肆渲染让吃瓜群众们第一次意识到一种令他们震惊的
  事实：原来还有一些安全漏洞是暂时没办法修复的，于是也就难免会“友邦惊诧”了。但他
  们并不知道的是其实在Spectre之前，研究者们就已经发展出各种令人眼花缭乱的攻击方
  式了，而对于其中的一些攻击方式，硬件厂商们同样是素手无策的，并且这也不是一天两
  天的事了。

  当然，说这些并不是为硬件厂商开脱，也不是否认Spectre的危害，只是想阐述一个事实
  ：其实类似级别的安全漏洞一直都存在，Spectre不是第一个，也不会是最后一个。此外
  ，Spectre的确有不同凡响的地方，这一点我们会在后面的章节中详细讨论。
  
* 原理：暂不讨论。

## 1.3 对行业的影响
仅仅因为一项研究结果就需要从本质上改变计算机的设计、运转方法，这种情况是非常罕见
的。Meltdown与Spectre做到了。这些发现将会改变未来7-10年（下一个CPU硬件周期）的软
件与硬件的设计思想 [[4]]。

## 1.4 安全漏洞披露原则
本次安全漏洞的披露与处理流程还是有一些问题的 [[3]]：
* Google在2017年6月1日发现了问题并把问题反馈给了部分硬件厂商，而FreeBSD直到圣诞
  节前的一周才得到通知，中间经历了足足6个多月的时间；

* 接下来Linux社区把事情变得更糟了，在得到通知之后他们并没有保持应有的缄默。一般
  情况下向多家厂商发布公告的标准流程应该是这样的：首先设置一个信息的封锁日期，在
  这个日期之前任何人不公开发表任何言论：不发布公告；不发布代码的补丁；不在公共邮
  件列表中讨论代码的补丁是否适用于不同的CPU。结果，尽管封锁日期被定为1月9日，在
  1月4日就有代码的补丁被发布出来，并通过互联网开始传播。

  作为行业惯例，从业者们通常会尊重所谓的responsible disclosure / 负责任的披露：
  在将一个安全漏洞向公众披露之前，会确保相关技术方会被提前通知以准备针对漏洞的补
  丁。但对本次事件某些环节的处理则显得有些披露有余而责任不足。

## 1.5 小结
在本章节中我们简单介绍了Meltdown与Spectre的一些背景，接下来我们将首先从一些基础
知识开始慢慢讲解Meltdown与Spectre的前世今生。出于个人偏好，除非特备声明，在本文
中我们的各种分析将主要基于Linux操作系统。

# 2. 内存
内存是用来存储程序的数据和代码的设备，内存中的每个字节（Byte）都有一个地址，内存
中字节的数量被称为内存的容量。

## 2.1 物理内存
物理内存就是指计算机中真实安装的内存条，物理内存的地址范围为[0, 真实容量)。

## 2.2 虚拟内存
虚拟内存是从进程的视角对物理内存的抽象，虚拟内存的地址范围为：

* 32位体系：[0, 2³²)，或；
* 64位体系：[0, 2⁶⁴)。

程序的进程，包括内核进程只使用虚拟地址，同一个虚拟地址空间对所有的进程都是可用的
（但这并不意味着，任何进程都有权访问整个虚拟地址空间）。每个进程的虚拟地址空间被
映射到独立的物理地址空间，因此即使不同进程的虚拟地址空间是完全相同的，它们实际上
使用的却是彼此独立的物理内存，相互间没有重叠（共享内存除外）。

## 2.3 虚拟地址
用来标记虚拟内存中每个字节的地址就是虚拟地址，为了便于表记，内存地址通常使用16进
制 [[63]] 来表示，例如：0x0000 0000，0xFFFF C7FF FFFF FFFF。

### 2.3.1 地址映射
将虚拟地址映射到物理地址的过程称为地址映射。

#### 2.3.1.1 直接映射
将一段连续的虚拟地址段直接映射到一段同样容量的连续的物理地址段，这种映射方式被称
为直接映射。直接映射中的虚拟地址也被称为逻辑地址：
physical-address = logical-address - ``PAGE_OFFSET``

注：``PAGE_OFFSET``为直接映射的虚拟内存地址段的起始地址。

#### 2.3.1.2 间接映射
直接映射的优点是简单：逻辑地址与物理地址一一对应，连续的虚拟地址段也对应连续的物
理地址段。然而，在现代的多任务操作系统中，物理内存需要被动态地分配给多个进程，不
能保证永远可以为一段虚拟内存找到一段同样大小的连续的物理内存，因此需要一种更灵活
的地址映射机制。间接映射将一个连续的虚拟地址段分割成若干尺寸相同的页 / page（默
认容量为4,096个Bytes)，每个页可以通过一个多级的Page Table Tree / 页表树映射到一
个同样容量的物理帧 / page frame，而这些物理帧并不需要彼此相邻。

页 / page是虚拟内存的一个单位，它的容量被称为页容量 / page size（默认容量为4,096
个Bytes，或4KB)，它的地址也必须与page size对齐（起始地址是page size的整数倍）。
页容量可以被修改为其它数值，如2MB。页帧 / page frame，或帧 / frame，是指一个容量
为page size，并且与page size对齐的物理内存块。虚拟地址空间中的页总是连续的，而物
理帧却通常并不连续。

尽管理论上地址映射可以通过软件实现，但是考虑到性能，这实际上并不可行，因此在现代
计算机中地址映射都是由一种被称为MMU / Memory Management Unit的硬件设备来完成的:
virtual-address => MMU => physical-address

页表定义了虚拟地址到物理地址的映射关系以及权限信息，如读权限、写权限、执行权限、
以及访问权限。

MMU通过一种被称为页表树 / Page Table Tree，或PT Tree的数据结构来建立虚拟页与物理
帧之间的一一对应关系。页表树是一棵单向的树，其中虚拟地址中的每一部分可以对应某一
级中的一个单元，因此每个虚拟地址可以在这棵树中选择一条从根节点到叶子节点的唯一的
路径，而叶子节点中保存着当前虚拟地址所对应的物理地址。

在x86 64位体系中，虚拟地址使用48位地址[[13]]，因此虚拟地址空间的容量为256TB。因
为页表是基于页进行地址翻译，因此一个虚拟地址与它的物理地址中的最低的12位是相同的
，因为最低的12位地址代表着某个字节在页内的偏移量，而一个逻辑页与一个物理帧一一对
应，因此页内偏移量不需要翻译。

逻辑地址剩下的36位可以被用来在页表树中选择一条路径。页表树有4层（从上而下分别被
称为PTL4， PTL3， PLT2，与PLT1），每一层包含多个页表 / PT。其中，每一个页表 / PT
恰好也是一个页（4,096个Bytes），包含512个页表单元 / PT Entry，或PTE（每个PTE的容
量为8个Bytes）。需要9位地址对512个PTE进行编址（2⁹=512），所以剩下36位地址中的每9
位地址可以对应一个PT中的一个PTE，最终在PT Tree中选择一条唯一的路径。

例如：我们可以模拟一下对0x644B321F4123这个虚拟地址的翻译过程 [[39]]。首先，地址
中最低的12位（0x123）不需要翻译，因此我们只需要翻译0x644B321F4000：
1. 在x86体系中，CPU的CR3寄存器保留着当前进程的PLT4的物理地址，因此可以从内存中读
   取PLT4的内容；
1. 取出0x644B321F4000中最高的9位地址0xC8（对应的十进制值为200），因此定位到
   PTL4[200]这个PTE；
1. PTL4[200]中保存着PLT3的物理地址，因此可以读取PTL3的内容；
1. 取出0x644B321F4000第2组的9位地址0x12C（对应的十进制值为300），因此定位到
   PTL3[300]这个PTE；
1. PLT3[300]中保存着PTL2的物理地址，因此可以读取PTL2的内容；
1. 取出0x644B321F4000第3组的9位地址0x190（对应的十进制值为400），因此定位到
   PTL2[400]这个PTE；
1. PTL2[400]中保存着PTL1的物理地址，因此可以读取PTL1的内容；
1. 取出0x644B321F4000第4组的9位地址0x1F4（对应的十进制值为500），因此定位到
   PTL1[500]这个PTE；
1. PTL1[500]中保存着与0x644B321F4000对应的物理地址，假设地址为
   0xFFFFFFFF56789000，这个地址是物理帧的起始地址，因此与12位页内地址对应的物理
   地址为0xFFFFFFFF56789123。

注意：在地址映射的过程中，虚拟地址的部分地址位会被保留，这一点非常重要。如果页容
量为4KB（12位页内地址），那么虚拟地址中最低的12位将会被保留；如果页容量为2MB
（22位页内地址），则虚拟地址中最低的22位会被保留。出于性能考虑，现代操作系统通常
默认启用对大容量页 / large page size的支持 [[5]]。

### 2.3.2 内核逻辑地址
Linux内核对某些特定的虚拟内存区域使用直接映射，这部分虚拟地址也被称为逻辑地址：
physial-address = logical-address - ``PAGE_OFFSET``。 程序可以通过kmalloc()函数
从直接映射区域申请内存。

### 2.3.3 内核虚拟地址
对于直接映射区域以外的虚拟内存空间，Linux内核使用间接映射。程序可以通过vmalloc()
函数从间接映射区域申请内存。

### 2.3.4 用户虚拟地址
用户的程序总是使用间接映射的方式来做地址映射。用户程序可以通过malloc()函数从用户
虚拟内存空间申请内存。

## 2.4 内存映射
操作系统通常会把虚拟地址空间划分成不同的功能区域，以Linux为例，虚拟地址空间会被
分成“内核空间”和“用户空间”两个区域。除此以外，在每个大区域内部还会细分成更多的小
区域。

### 2.4.1 X86 32位体系
在32位的体系内，内存地址为32位，系统可以管理的最大虚拟内存容量为4GB
（2³²个Bytes），其中1GB = 2³⁰个Bytes，地址范围为0x0000 0000 ... 0xFFFF FFFF：
[0, 4GB) [[10]]

在这4GB的空间内，内存的映射如下：

0x0000 0000 ... 0xBFFF FFFF：用户空间、3GB、使用间接地址映射

0xC000 0000 ... 0xFFFF FFFF：内核空间、1GB，其中:

* 0xC000 0000 ... 0xF7FF FFFF：内核代码与数据、896MB、直接映射。

  physical-address = logical-address - ``PAGE_OFFSET``

  ``PAGE_OFFSET`` = 0xC000 0000

  注意：Linux内核代码段的默认起始地址为0xC010 0000 [[47]]，因此内核默认情况下会
  被载入物理地址为0x0010 0000 (1MB)的物理内存中。

  直接映射区域只能映射896MB的物理内存。但是Linux内核需要可以访问到整个物理内存，
  如果物理内存超过896MB，内核将如何访问呢？这就是下面这个内存区域的作用。

* 0xF800 ... 0xFFFF FFFF：128MB、间接映射。
  这部分内存区域使用间接映射，可以用来访问超出896MB的物理内存（称为high memory）
  ，通过使用这部分虚拟内存区域，内核可以访问到整个物理内存空间（当然内核仍然无法
  同时访问所有的物理内存，而只能通过这个区域，每次访问一部分high memory）。

### 2.4.2 X86 64位体系
在64位的体系内，内存地址为64位，而因为实际的物理内存远远达不到这个级别，因此通常
操作系统只使用其中的48位作为内存的地址，因而系统可以管理的虚拟内存容量为
256TB（2⁴⁸个Bytes），其中1TB = 2⁴⁰个Bytes。[[12]] 

因为只使用了64位中的48位来为内存编址，因此需要某种规则可以很容易地把那些没有编址
的地址空间标记出来：一个合法的内存地址中最高的16位（48位...63位）必须与47位相同
（与符号位扩展的方法相同）。所有不符合这条规则的地址都是非法的地址，而符合这种规
则的地址被称为规范地址 / cannonical form address [[13]]。

在这256TB的空间内，内存的映射如下：

0x0000 0000 0000 0000 ... 0x0000 7FFF FFFF FFFF：47位、用户空间、128TB、间接映射

0x0000 8000 0000 0000 ... 0xFFFF 7FFF FFFF FFFF：43位、未使用、非规范地址空间 

0xFFFF 8000 0000 0000 ... 0xFFFF FFFF FFFF FFFF：47位、内核空间、128TB、其中：

* 0xFFFF 8000 0000 0000 ... 0xFFF8 7FFF FFFF FFFF：43位、保留空间（未使用）

* 0xFFF8 8000 0000 0000 ... 0xFFFF C7FF FFFF FFFF：64TB、直接映射

  physical-address = logical-address - ``PAGE_OFFSET``

  其中``PAGE_OFFSET``=0xFFF8 8000 0000 0000

  具体逻辑可以参照``__phys_addr_nodebug()`` [[15]] 函数的定义。

  目前Linux只支持64TB的物理内存，因此这个区域刚好可以映射整个物理内存，因此与32
  位的体系不同，64位体系中没有所谓的high memory。

* 0xFFFF C800 0000 0000 ... 0xFFFF C8FF FFFF FFFF：40位、保留空间（未使用）

* 0xFFFF C900 0000 0000 ... 0xFFFF E8FF FFFF FFFF: 45位、间接映射区域

* ...

* 0xFFFF FFFF 8000 0000 ... 0xFFFF FFFF 9FFF FFFF：512MB、内核代码段

  直接映射 + ``CONFIG_PHYSICAL_START``：

  physical-address = logical-address - offset

  offset = ``START_KERNEL_map`` - ``CONFIG_PHYSICAL_START`` 

  例如、内核代码段起始地址计算如下：

  offset = 0xFFFF FFFF 8000 0000 - 0x1000 0000 = 0xFFFF FFFF 7000 0000

  physical-address = 0xFFFF FFFF 8000 0000 - 0xFFFF FFFF 7000 0000 = 0x1000 0000
   = 16MB

  具体逻辑可以参照``__phys_addr_nodebug()``函数的定义

* ...

## 2.5 内存隔离
本章的内容与Meltdown有很重要的关联，因此请仔细阅读。

计算机系统安全的基础是内存隔离：内核地址范围被标记为不允许用户进程访问；用户进程
不允许访问彼此的内存（共享内存除外）。

在现代CPU中，内核与用户进程之间的隔离通常是由一个比特位实现，这个比特位定义一个
内核的页是否可以被访问。基本思想是这个比特位只有进入内核进程才能被设置，当切换到
用户进程的时候这个比特位被清零。这一硬件特性允许操作系统将内核空间映射到每个用户
进程的地址空间内，从而可以快速地从用户进程切换到内核进程，例如中断处理。

注意：因为内核通常被映射到用户进程地址空间，对用户进程而言，虽然内核是不可访问的
，却依然可以被寻址。换言之，用户进程仍然可以构造一个内核的虚拟地址并试图访问这个
地址，尽管这会触发一个页错误。

为了将进程彼此隔离，当前进程的PTL4的物理地址地址被保存在CPU的一个寄存器中。当进
程切换时，操作系统将下一个进程的PTL4的地址写入寄存器，从而为每个进程提供独立的虚
拟地址空间。因此每个进程只能访问到属于它自己的虚拟地址空间。所以进程A无法构造一
个进程B的虚拟地址，因为所有进程的虚拟地址空间都是相同的，进程A所构造的虚拟地址只
可能由它自己的页表翻译成物理地址，而除了共享内存段外，进程之间的物理地址是没有重
叠的。

每个虚拟地址空间本身又被分割成为两部分：用户空间、内核空间。用户空间可以被当前进
程访问，内核空间只有当前进程运行于内核状态时才能被访问。操作系统通过在页表中禁用
用户访问属性来加强这一特性。

内核地址空间不仅仅包含内核本身的映射，它也需要对用户的内存进行各种操作，例如在用
户的内存页中写入数据。因此，内核地址空间通常会映射整个物理内存：

在32位体系中，896MB以下的物理内存直接映射到内核地址空间中，其余的物理内存
作为high memory通过间接映射到内核地址空间中。

在64位体系中，整个物理内存（64TB）被直接映射到0xFFF8 8000 0000 0000。

因此用户空间中某个地址所对应的物理地址，也必然在内核空间中有一个与之对应的虚拟地
址，在64位体系中，通过直接映射，在32位体系中，通过直接映射 + 间接映射high memory
。

注意：以上的所有事实形成了一个操作系统中潜在的弱点，攻击者可以利用这个弱点发起
Meltdown攻击，我们会在后面的章节详细讨论。

### 2.5.1 KAISER
KAISER / Kernel Address Isolation to have Side-channels Efficiently Removed
 [[61]]，也被称为Kernel Page-table Isolation (KPTI or PTI) 是由 Gruss et al. 提
交的一个内核补丁，这个补丁实现了内核与用户地址空间之间更强的隔离。除了x86架构必
须的一些内核地址空间外（例如：中断处理），KAISER不把其余任何内核地址空间映射到用
户地址空间。因此，在用户地址空间中不存在到整个内核地址空间或整个物理地址空间的映
射，这类地址也就法被解析了。

## 2.6 Intel TSX
Intel TSX是Intel对Hardware Transactinal Memory / 支持硬件事务的内存（HTM）的实现
。一个事务由_xbegin()开始，由_xend()结束（提交），并且一个事务中的所有指令为原子
级别的，即要么全部成功，要么全部失败。一个事务有可能失败（终止）：例如，当两个或
更多并发的事务彼此影响，或发生任何安全错误：如段错误，页错误，或发生中断。当一个
事务被终止，所有的修改将被撤销（回滚），并且由用户事先编写的abort handler会被调
用。

## 2.7 ASLR
ASLR / Address Space Layout Randomization [[41]] 是一种将程序地址空间随机化的机
制，每一次程序被载入内存，包括程序的代码段与数据段在内的一些内存段都会被载入随机
的地址。因此那些针对特定地址的攻击者会因为无法确定准确的攻击位置而失效，而这些攻
击者如果想继续发起有效攻击，则必须先击败ASLR。

### 2.7.1 实现
当ASLR被启用的时候，内存段原始的虚拟地址首先被操作系统转换为一个随机地址，这个随
机地址最后被翻译成为物理地址。在这个过程中，只有原始地址中的一部分地址位
（称为“entropy/熵”），被随机化。entropy受内存段的容量与对齐单位影响。出于性能与
内存使用效率考虑，对齐单位通常为页容量的整数倍，如：4KB、16MB等。

例如：在64位系统中的一个大小为1GB（2³⁰），对齐单位为4KB（2¹²）的内存段，最多可以
使用18位entropy（12位...29位）。

### 2.7.2 击败ASLR
击败ASLR有两种方式：绕过或破解。

#### 2.7.2.1 绕过ASLR
所谓跳过ASLR，是指在某些传统攻击方式中，通过某些技巧规避ASLR，继续发动攻击。在这
种方式中，攻击者其实仍然并不知道被随机化的地址是什么。我们以比较常见的
Stack Buffer Overflow攻击为例来简单说明。

##### 2.7.2.1.1 传统的Stack Buffer Overflow攻击
Stack Buffer Overflow [[45]] 利用代码中缺少对数组越界检查的缺陷，通过向程序传送
超出数组容量的数据，从而将攻击者代码（shellcode）的地址写入栈，最终导致代码跳转
至shellcode。

##### 2.7.2.1.2 ret2libc攻击
为了应对Stack Buffer Overflow攻击，操作系统引入了W^X特性，从而禁用栈空间的执行权
限。因为在传统的Stack Buffer Overflow中，shellcode必须被保存在栈内。如果栈空间没
有执行权限，攻击也就失效了。

针对W^X特性，攻击者又发明了ret2libc [[45]] 攻击。这种攻击不需要shellcode，攻击者
通过Stack Buffer Overflow攻击将libc中某个函数，如``system()``的地址以及参数如
"/bin/bash"写入栈，从而导致代码跳转至``system("/bin/bash")``，以目标用户的身份打
开一个bash终端。

##### 2.7.2.1.3 ret2plt攻击
为了应对ret2libc攻击，操作系统引入了ASLR机制，因为无法确定``system()``的地址，攻
击也就失效了。攻击者又发展出了ret2plt [[57]] 攻击，在这种攻击方式中，攻击者可以
通过function@PLT来间接调用libc的函数，而并不需要知道libc函数的地址，因此相当于绕
过了ASLR。

#### 2.7.2.2 破解ASLR
破解ASLR是指彻底计算出原始虚拟地址被随机化以后的地址。

##### 2.7.2.2.1 Bruteforce Attack / 暴力破解
所谓暴力破解就是通过遍历所有可能的地址来实施攻击，例如通过遍历所有可能的libc函数
地址来发起Stack Buffer Overflow攻击。这种方法在entropy位数比较少的情况下是可行的
，因此一般情况下只适用于32位操作系统 [[58]]。

##### 2.7.2.2.2 Format String + Info Leak攻击
Format String攻击 [[42]] 利用程序中缺少对``printf()``中format string的检查的缺陷
，通过向printf()传递越界的format string来输出栈内的某个指针的值（这种攻击方式也
被称为Info Leak），这个指针的值可能是某个libc函数的地址，把这个地址作为起始地址
，根据libc中其它函数与这个函数的相对位置，就可以计算出其它函数，如``system()``的
地址，并发动进攻。

##### 2.7.2.2.3 AnC攻击
2017年2月15日发布的AnC [[39]] 白皮书提供了一种很有趣的视角来看待MMU。它通过监控
MMU对页表的访问时间（页表是否被缓存会影响访问时间）来计算随机化以后的地址，从而
最终破解ASLR。作者提供了C语言的示例代码并展示了基于JavaScript的攻击的演示视频。
这是第一篇完整展示对ASLR的成功攻击的论文，以往的论文仍停留在理论层面，甚至没有提
供任何POC / 概念证明。尽管AnC看上去是一种针对ASLR的通用的攻击方法，我们仍需牢记
这种攻击方法只适合攻击那些允许运行攻击者代码（即使这种代码是解释执行的脚本）的应
用程序，例如FireFox或Chrome浏览器。即便如此，如果脚本语言不提供时间戳API，依然无
法施展这种攻击。

注意：因此AnC不适用于破解本地或远端独立应用程序的ASLR。

##### 2.7.2.2.4 BTB攻击
BTB [[38]] 白皮书详细介绍了一种通过对BTB（Branch Target Predicator）发起边信道攻
击来破解ASLR的技术。然而，作者的论文存在一些自相矛盾的叙述，并且没有提供任何示例
代码或步骤来支持第三方的独立分析。因此，有其他研究者对这篇论文的有效性表示了质疑
 [[32]]。

#### 小结
ASLR通过将程序的不同内存段载入随机地址来有效预防那些对特定位置发起的攻击，因此攻
击者要发起有效攻击必须先绕过或破解ASLR。尽管ASLR已经存在了很久，并且攻击者也发展
出了很多针对ASLR的攻击方法，但这些方法都有其局限性，只适用于某些特殊场景，到目前
为止，并不存在一种通用的攻击ASLR的方法。

注意：ASLR的初衷主要是针对远程攻击，本地攻击者有更多击败ASLR的可能性：例如攻击者
可以通过其他攻击手段获得更高权限，从而通过调查/proc/PID/maps来获取重要的地址信息
，或者在有些系统中共享库在所有程序中的虚拟地址都是相同的，而攻击者可以发起
ret2libc攻击来获得更高权限等等。

## 2.8 KASLR
KASLR / Kernel Address Space Layout Randomization，KASLR在每次内核重新启动的时候
，将内核的地址空间随机化。将程序地址空间随机化的目的是增加攻击的难度，因为攻击者
必须猜测攻击目标的地址。

### 2.8.1 实现
以64位Linux为例，KASLR的熵由内核地址区域（例如：1GB - 16GB）与地址对齐单位（通常
是page size的整数倍，如4KB - 16MB）决定 [[40]]。

注意：在目前的Linux版本中，当KASLR被启用，内核映射区域由512MB变为1GB [[22]]：
linux/arch/x86/include/asm/``page_64_types.h``
63行：
```c
/*
 * Kernel image size is limited to 1GiB due to the fixmap living in the
 * next 1GiB (see level2_kernel_pgt in arch/x86/kernel/head_64.S). Use
 * 512MiB by default, leaving 1.5GiB for modules once the page tables
 * are fully set up. If kernel ASLR is configured, it can extend the
 * kernel page table mapping, reducing the size of the modules area.
 */
#if defined(CONFIG_RANDOMIZE_BASE)
#define KERNEL_IMAGE_SIZE	(1024 * 1024 * 1024)
#else
#define KERNEL_IMAGE_SIZE	(512 * 1024 * 1024)
#endif
```

例如，Linux的内核地址范围为1GB（30位），内核代码页的地址对齐单位为16MB（24位），
因此KASLR熵只有6位，即64个可能的随机值。内核起始地址备选值如下：
base-address + s * align-size: 0 <= s < 64

0xFFFF FFFF 8000 0000

0xFFFF FFFF 8100 0000

0xFFFF FFFF 8200 0000

...

0xFFFF FFFF BFFF FFFF

同理，Linux内核模块的熵为10位，对齐单位为4KB，可能的起始地址有1,024个。

### 2.8.2 破解KASLR

#### 2.8.2.1 背景
KASLR并非不可破解，这里我们介绍一种被称为DrK [[40]] 的技术来破解KASLR。DrK基于以
下事实：读取一个内核地址，如果这个地址没有被映射到任何物理地址，则读取时间 > 235
个时钟周期; 否则读取时间 < 220个时钟周期；如果这个地址有对应的物理地址，执行这个
地址的内容，如果这个地址所在的页有执行权限，访问时间 < 200个时钟周期；否则，访问
时间 > 220个时钟周期。

#### 2.8.2.2 破解流程
首先列出所有可能的内核起始地址与内核模块起始地址，并对其中的每一个地址执行如下流
程：
1. 启动Timer；
1. 启动一个TSX事务；
1. 尝试读取或执行当前地址；
   注意：因为这个地址属于内核地址空间，这个操作不会执行，而当前事务会终止。
1. 在Abort Handler中停止Timer，检查时间间隔；

通过对每一个备选地址执行以上步骤，可以确定内核代码页与内核模块页的起始地址。因为
内核代码页是直接映射到连续的物理内存块，它结束于第一个未映射的地址。对于模块页，
虽然每个模块被映射到连续的物理内存，模块与模块之间是通过未映射页来分隔的，因此在
这个区域找到的未映射页只能告诉我们有多少个模块加载到这个区域。可以利用当前被加载
的模块数量来间接确定内核模块区域的结束位置，这可以通过操作系统中的lsmod命令来获
得。如果找到的未映射地址的数量与模块数相同，则内核模块的地址空间结束在那个未映射
地址。

#### 2.8.2.3 小结
本章节中提及的DrK攻击可以破解KASLR。

# 3. 处理器
简单地说CPU / 处理器是计算机中负责执行代码的硬件设备。

## 3.1 缓存
CPU的高性能与内存的低性能之间的巨大差距导致大多数时候CPU都需要等待内存，这对计算
机运算能力造成了巨大的浪费。为了改善这种现状，现代的计算机系统在CPU与内存之间，
引入了若干层高速存储设备，称为cache / 缓存。通常，缓存分为三级，按照距离CPU的距
离由近到远依次为：L1 cache / 一级缓存、L2 cache / 二级缓存、L3 cache / 三级缓存
（也被称为LLC - Last Level Cache）。距离CPU越近的缓存，速度越快，价格越昂贵，容
量也越小。

其中L1 cache又分为缓存数据的L1d，与缓存代码的L1i，每个CPU的核心有独立的L1
cache；L2 cache可以缓存数据与代码，每个CPU核心有独立的L2 cache；LLC可以缓存数据
与代码，所有CPU的核心共享LLC。

在本文中，我们将主要讨论LLC。

### 3.1.1 传统缓存基础
缓存与内存类似，也是一种存储设备，因此缓存也需要解决两个问题：寻址和结构。

#### 3.1.1.1 结构
传统缓存可以批量存储的最小单位为64个Bytes，称为一个cache line；若干（w）个cache 
line被编为一组，称为一个w路的cache set；所有的cache set构成缓存整体。

例如，某个CPU有2MB，16路的LLC，那么缓存的结构如下：

* Cache Line Size = 64B
* No. of Cache Line = 2MB / 64B = 32,768 (32K)
* No. of Cache Sets = 32K / 16 = 2,048 (2K)

注意：Intel CPU中缓存的Set数量总是2,048个。

LLC总容量为2MB；这2MB容量为分割为32K个cache line；每个cache
line的容量为64B；每16个cache line被编为一组（16路的cache set）；共组成2,048
（2K）个cache set。 

#### 3.1.1.2 寻址
当程序需要访问某个虚拟地址，这个虚拟地址首先被MMU翻译为物理地址，随后系统将这个
物理地址翻译为缓存的地址，并以``此``给出结论：程序可以直接从缓存中获取所需内容
（cache hit / 缓存命中），或程序需要从内存获取所需内容
（cache miss / 缓存未命中），具体细节如下：
* 缓存中某个字节的完整地址构成为：tag|index|offset。
* 内存的物理地址中的最低6位被映射到缓存的offset字段（表示字节在一个cache line中
  的地址，因为每个cache line的容量为64个Bytes = 2⁶个Bytes）；
* 接下来的11位被映射到缓存的index字段（代表cache set的地址，因为set总量为
  2,048 = 2¹¹）；
* 剩余的地址位被映射到
  缓存的tag字段（用于检验缓存是否命中）。

我们前面只提到一个cache line包含64个Bytes的数据，事实上，它的结构如下：
tag | 64个Bytes | flag bits

因此，一个cache line中所有字节的tag都相同。

缓存寻址过程如下：
1. 物理地址被映射为tag，index，与offset字段；
1. 通过index定为到一个cache set；
1. 将这个tag与cache set中每个cache line的tag比较，如果找到一个匹配，则表示缓存命
   中，否则未命中。

### 3.1.2 现代缓存基础
现代Intel CPU，从Sandy Bridge开始，将LLC中的cache set进一步编为若干组，称为slice
，每个slice对应一个CPU核心。

#### 3.1.2.1 结构
系统通过一个hash函数（函数的算法未公开）[[52]] 将物理地址映射到slice 的编号。LLC
被一个环形总线连接。每个CPU核心被分配一个slice，但是所有的CPU核心均可以通过这个
环形总线访问到所有其它的slice。所以，cache line被编入cache set，而cache set 被编
入slice。

例如：

Sandy Bridge H2 CPU有2个核心，4MB 16路LLC。缓存的结构如下：

* Cache Size: 4MB, 16路
* Cache Line Size: 64B
* No. of Slices: 2 （与CPU核心数量相同）
* No. of Cache Lines: 4MB / 64B = 65,535 (64K)
* No. of Cache Sets: 64K / 16 = 4,096 (4K)
* No. of Cache Sets / Slice = 4,096 / 2 = 2,048 (2K)

注意：在这种缓存结构中，不同slice中的两个cache set的index可以相同。

#### 3.1.2.2 寻址
* 物理地址中的最低6位仍然被映射到缓存的offset字段；
* 接下来的11位仍然被映射到index字段；虽然现在cache set总量超过2K，11位仍是足够
  的，因为cache set被编入不同的slice中，而每个slice中仍然只有2,048个cache set；
* 剩余的地址位仍然被映射到缓存的tag字段；
* 物理地址（包括tag, set index，但不包括offset）被再次使用，系统通过一个hash函数
  （算法未公开）将这部分物理地址映射到一个slice id，从而确定应该使用哪一个slice
  。如果CPU核心的数量是2的指数，hash函数只用到tag，而不使用set index。
  注：Sandy Bridge的hash函数已经被逆向工程破解。

寻址过程：
1. 物理地址被映射为tag，index，与offset；
1. 物理地址的一部分被hash函数映射为slice id；
1. 通过slice id与index定位一个cache set；
1. 将tag与cache set中每一个cache line的tag进行比较，如果发现匹配则缓存命中，否则
   未命中；

### 3.1.3 淘汰策略
缓存比内存小得多，因此缓存总会被装满的。当缓存满了以后，就必须有所谓的淘汰算法来
决定那些缓存的内容被移除。

#### 3.1.3.1 LRU
LRU / Least Recently Used算法把最不常用的内容移除缓存（将新加入的cache line放在
MRU位置）。

#### 3.1.3.2 BIP
BIP / Bimodal Insertion Policy，大部分时间将新加入的cache line放在LRU位置，这与
LRU的算法相反。

#### 3.1.3.3 自适应策略
自适应淘汰策略 [[24]] 尝试通过分析缓存的访问模式
（cache line被淘汰之前是否被访问）来选择合适的淘汰策略：LRU或BIP。因此，如果要训
练CPU使用LRU策略，可以在每个memory line在载入缓存以后，再反复访问它几次，以通知
CPU这条cache line在被淘汰之前被访问过。

### 3.1.4 Inclusiveness / 包容性
大部分现代CPU（包括Intel CPU）中的LLC都是具备包容性的，意味着所有存在于L1与L2缓
存中的内容，必然也存在于LLC中，这会进一步导致两个事实：

* 首先，被任何一个CPU核心访问的数据，必然会被载入L1缓存与LLC；

* 其次，从LLC中淘汰的任何数据，必然也会从L1与L2 Cache中淘汰。

注：缓存的包容性是基于缓存的攻击的基础。

### 3.1.5 Prefetching / 预取
通过硬件手段、软件手段，或两者的组合，数据可以在被使用之前载入缓存，这被称为预取
/ prefetching。本章会讨论Intel Sandy Bridge CPU中的各种硬件预取机制。执行预取的
硬件设备被称为prefetcher / 预取器。Prefetcher的目的是自动预测程序将会使用哪些数
据。prefetcher每次从内存读入与cache line相同容量的数据，称为一个memory line
 [[36]] [[53]]。

#### 3.1.5.1 L1缓存Prefetcher
L1缓存有两种prefecher：DCU、与基于IP的prefetcher。

##### 3.1.5.1.1 DCU
DCU / Data Cache Unit，也被称为next-line prefetcher，或streaming prefetcher。如
果它检测到当前cache line在某个时间窗口内被多次反复访问，则认为下一个memory line
会被用到，于是预先将下一个memory line从L2缓存或内存读入L1缓存。

例如：
```c
for (i = 0; i < 10; i++) {
    a = data[i * 64];
    // additional loads of current cache line trigger the DCU prefetcher to
    // prefetch the next cache line.
    a = data[i * 64]; 
    a = data[i * 64];
 
    // Load next cache line, which should have been prefetched.
    b = data[(i + 1) * 64]
}
```

##### 3.1.5.1.2 基于IP的Prefetcher
基于IP (Instruction Pointer)的prefetcher，也被称为stride / 跨度prefetcher。这个
prefetcher 追踪每一条load指令。如果某一条指令被发现有固定的跨度，则下一个地址的
数据会被预先读取。next-address = current-address + stride。这个prefetcher可以向
前或向后预取数据，并可以检测最高半页 / 2KB的跨度。

注意：IP prefetcher只使用虚拟地址中最低的8位来区分地址。因此，如果两条load指令所
使用的地址的最低8位相同，则IP prefetcher会被限制。

假设：
* data是一个字节数组
* data[0]是一个memory line的第一个字节（按照64个Bytes对齐）。
* 1个memory line = 64个Bytes

例子：
```c
for ( i = 0; i < 10; i++) {
    a = data[i * 32];
    // the stride is 32个Bytes, which is half of the size of a cache line,
    // so data[i * 32] and data[i * 32 + 32] reside in the same cache line.
    // When data[i * 32] is fetched and cached, data[i * 32 + 32] will be
    // fetched and cached in the same cache line.
}

// data[0] is fetched normally, a cache line is fetched and cached
// data[1* 32] is already cached, stride of 32 is detected, counter = 1
// data[2 * 32] is fetched normally, stride of 32 is detected, counter = 2
// data[3 * 32] is already cached, stride of 32 is detected, counter = 3, 
// data[3 * 32 + 32] is PREFETCHED, counter = 4
// data[4 * 32] is already cached, stride of 32 is detected, counter = 5, 
// data[4 * 32 + 32] is PREFETCHED
// ...

for (i = 0; i < 10; i++) {
     a = data[i * 256];
     // The prefetcher won't work, because the lower 8 bits of each address
     // are same.
}
```

#### 3.1.5.2 L2缓存Prefetcher
L2缓存有三种prefetcher：DPL、Spatial、与Streamer。这些prefetcher将数据预取到L2缓
存与LLC缓存。

##### 3.1.5.2.1 DPL
DPL / Data Prefetch Logic 根据DCU请求的历史纪录将数据预取至L2缓存。DPL监控来自
DCU的递增的顺序读取，称为stream / 流。一旦DPL检测到一个流中的第二个读取请求，它
就会预取下一个memory line。例如，当DCU请求了line A，和line A+1，DPL则认为DCU很快
将会请求line A+2（此时DPL检测到了第一个stream请求）。如果接下来DCU请求了line A+2
（第二个stream请求），那么DPL将会预取line A+3。

注意：Intel CPU中的DPL可以预取最多8条memory line。

例子：
```c
a = data[0*64];
a = data[0*64];
a = data[0*64];
// Triggers DCU to prefetch the next cache line, which contains data[1*64];
// The load request for data[1*64] is sent to L2 cache, and data[1*64] is
// loaded to L2, then L1 subsequently.

// data[1*64] already resides in L1 and L2
a = data[1*64];
a = data[1*64];
a = data[1*64];
// Triggers DCU to prefetch data[2*64] from L2, which load data[2*64] from
// memory subsequently.

a = data[2*64];
a = data[2*64];
a = data[2*64];
// Triggers DCU to prefetch data[3*64] from L2, which loads data [3*64] from
// memory, and will prefetch data[4 * 64] from memory.
```

注：因此可以粗略地认为DPL与DCU串联在一起。

##### 3.1.5.2.2 Spatial
Spatial prefetcher（Sandy Bridge）会尽量为每一个载入L2缓存的memory line额外载入
下一个相邻的memory line，以配对成为一块与128个Bytes对齐的内存。

例子：
```c
a = data[0 * 64];
// data[0 * 64] is fetched into L3, L2, then L1 normally. After that, data[1*64]
// is prefetched into L3 and L2.
```

##### 3.1.5.2.3 Streamer
Streamer prefetcher来自L1的递增或递减的顺序请求。被监控的读取请求包括由L1数据缓
存的load与store操作生成的请求，来自硬件prefetcher（DCU或IP）的请求，以及由L1指令
缓存生成的请求。当检测到增量或减量的顺序请求时，预期的cache line会被预取。

Streamer与Spatial prefetcher一定会把数据载入LLC。通常，只要L2缓存没有被大量未命
中请求占用，数据也会被载入L2缓存。

* Streamer可以最多预取20条cache line；
* 那些领先当前进度太多的cache line只会被载入LLC，这可以防止从L2中淘汰有用的cache
  lines。

注：因此可以粗略地认为Streamer分别与DCU、DLP串联在一起。

#### 3.1.5.3 LLC缓存Prefetcher
LLC实际上并没有自己的prefetcher，但是根据前面的讨论，Spatial与Streamer可以顺便将
数据预取到LLC。

#### 3.1.5.4 限制
* 所有的prefetcher预取的数据必须只存在于一个4KB的页内，不能跨页；
* IP prefetcher只用到地址中最低的8位来区分地址，如果两个请求中地址的最低8位相同
  ，则IP prefetcher会被限制；
* DPL可以预取最多8个cache lines；
* Streamer可以预取最多20个cache lines;

## 3.2 Out-of-order Execution / 乱序执行
Out-of-order Execution / 乱序执行 [[43]] 是一种技术范式，它允许一条指令在CPU完成
其所有前置指令之前被执行。乱序通过允许程序指令并行于，甚至先行于其前置指令执行，
来提高CPU执行单元的利用率。CPU将执行完成的指令存储在reorder buffer中。
Reorder buffer中的指令将按照原始顺序retire / 退休。换言之，一条指令，只有当它所
有的前置指令都已完成并已退休，才能退休。只有当一条指令退休的时候，其执行结果才被
提交（对外界可见）。

例1：
```c
raise_exception();
// 当前指令（抛出例外）比较耗时，在它执行完毕之前，CPU会尝试预执行它的后继指令。
// 在本例中，当前指令完成以后，预执行指令的结果会被撤销。
access(probe_array[data * 4096]);
```

例2：
```c
if (x < array1_size) {
    // 当前分支语句的跳转目标依赖于array1_size的值，它此时正在被载入寄存器。此时
    // ，CPU将会猜测分支的目标，并尝试预执行这个目标的代码。
    // 在本例中，CPU猜测条件语句的值为TRUE，因而将预执行分支内的指令。
    // 当array1_size的值最终被载入后，如果分支语句的结果为TRUE，则提交预执行指令
    // 的结果，否则撤销。
    y = array2[array1[x] * 256];
}
```
### 3.2.1 Branch Prediction / 分支预测
在分支语句（包括：conditional branch / 条件分支，与indirect branch / 间接分支）
之后乱序执行需要CPU猜测分支语句可能的结果。好的预测可以增加能够被成功提交的预测
执行的数量，从而改善性能。有若干CPU组件被用来预测分支语句的结果。分支预测分为两
个步骤：第一步预测分支是否被taken，这一步被称为branch prediction，对应的硬件被称
为branch predictor [[30]]，间接分支永远被预测为taken；第二步对于被taken的分支，
预测分支的目标，这一步被称为branch target prediction，对应的硬件被称为
Branch Target Buffer (BTB)。

Branch Target Buffer (BTB) 保存着从最近执行的分支语句的地址到其目标地址之间的映
射。源地址（分支指令的地址）被用来作为BTB的索引，称为address tag。出于性价比考虑
，现代CPU通常只在address tag中保存源地址中部分高段地址位，而忽略其余高段地址位。
Evtyushkin et al.曾研究过Intel Haswell CPU中的BTB，并声称只有最低的30位地址被用
于address tag。而Spectre的研究者发现在他们的实验中只有最低的20位 [[44]] 被用于
BTB的address tag。

CPU可以用BTB来预测未来的代码地址，这甚至可以发生在解码分支指令之前。

对于条件分支语句，只记录目标地址是不足以用来预测分支结果的。为了预测分支的跳转方
向，处理器还保存着最近执行的条件分支语句的结果。

### 3.2.2 Speculative Execution / 预测执行
Speculative execution / 预测执行 [[43]] 特指位于条件分支语句后面的乱序执行。

例1:
```c
if ( x < array1_size) {
    y = array2[array1[x] * 256];
}
```

## 3.3 Hyper-Threading / 超线程
Intel的Hyper-Threading [[27]] 技术可以在一个CPU核心内实现多个逻辑CPU核心（如两个
逻辑CPU核心），操作系统可以将逻辑CPU核心等同于物理CPU核心来使用，因此可以增加程
序的并发性。例如：如果一个CPU核心提供两个逻辑CPU核心，那么对于一个4核的CPU而言，
就相当于提供了8个逻辑CPU核心，对操作系统而言，相当于最多可以同时有8个线程并发执
行。运行于逻辑CPU核心上的线程被称为Hyper-Thread / 超线程。超线程技术实际上可以近
似地理解为Intel在硬件层面的多线程实现。在后面的讨论中，我们可以了解到，运行于同
一个物理CPU核心上的超线程之间是可以共享branch predictor / 分支预测数据的 [[44]]
。而这是spectre攻击的一个先决条件。

# 4. Covert-channel Attacks / 隐蔽信道攻击
在计算机安全领域，covert channel / 隐蔽信道 [[62]] 是一种安全攻击，这种攻击可以
可以在本不被计算机安全策略允许彼此通讯的进程之间传输数据。有两种类型的隐蔽信道攻
击：存储隐蔽信道，与时间隐蔽信道。

## 4.1 存储隐蔽信道
下面这个例子可以说明什么是存储隐蔽信道。这有点类似于谍战片中的dead drop / 死投，
假设我在某个论坛帖了一张图片，虽然大家都能看到，但是除了你，没人能明白图片中的隐
藏信息。这个隐藏信息或者被隐藏在图片的像素数据中，或者是某种事先约定好的协议：
“如果我帖一张茶壶壶嘴朝左的图片，表示中午发动进攻；如果壶嘴朝右，表示半夜进攻；
如果我帖一张茶杯的图片，表示计划暂停”

## 4.2 时间隐蔽信道
另外一种隐蔽信道可以通过改变正常通讯的时间延迟来实现。想象这样一个场景，一段流媒
体视频时不时地中断；这很容易被理解为系统或者网络问题。然而，中断的时间长短可以被
用来传送数据：例如一个长的中断，伴随着一个短的中断，可以用来代表摩尔斯编码中的N
。

## 4.3 区别
两者的主要区别是存储隐藏信道会留下一些证据，但不需要接收方监听数据；而时间隐藏信
道几乎不留痕迹，但是需要信息的接收方同步监听数据。

# 5. Side-channel Attacks / 边信道攻击
在计算机安全领域，side-channel attack / 边信道攻击是指任何基于计算机系统的物理实
现，而非系统缺陷所获取的信息而发动的攻击。时间信息、电力消耗、电磁泄露、甚至声音
都是可以提供额外信息的来源，并可以被利用来破解系统。

例如：

电磁边信道攻击：攻击者通过监控电传打字机泄露的电磁波来检测按键动作。

声音边信道攻击：攻击者通过监听打印机的声音来推测打印的内容。

## 5.1 缓存边信道攻击
基于缓存的边信道攻击利用“进程之间共享缓存”这一事实，通过类似时间、冲突等边信道来
侦测缓存的状态，从而间接获取敏感数据。在本文中，我们将主要讨论LLC，因为CPU的核心
共享LLC。此外，LLC的inclusiveness / 包容性是跨CPU核心攻击的基础。

### 5.1.1 Prime + Probe
Prime + Probe [[51]] 是一种让攻击者发现victim / 被攻击程序访问了哪个cache set的
通用攻击术。与Flush + Reload不同, Prime + Probe不依赖共享内存。

攻击者A运行一个间谍进程来监控被攻击程序V的内存使用情况：

* Prime：A用自己的数据填充一个或多个cache set；

* Idel: 当V执行并使用内存的时候，A等待一段预先定义好的时间；

* Probe：A继续执行并监控再次填充这些cache set所用的时间；如果V已经淘汰了A的某些
  cache line，那么A将会在这些cache line上花费更长的时间；

* 当Probe阶段完成cache set的填充，它又成为下一轮攻击的Prime阶段。

通过观察缓存的状态，可以侦测出V使用内存的模式，在某些情况下这可以被用来破解系统
对敏感信息的保护。

#### 5.1.1.1 挑战与解决方案

##### 5.1.1.1.1 观察所有CPU核心的内存访问
利用LLC的包容性，可以从所有的缓存中淘汰victim的数据，而不需要访问运行victim的CPU
核心的私有缓存。

##### 5.1.1.1.2 缩短Probe时间
首先在victim找到少数几个对安全很关键的内存访问，并找到与这些访问相关的那些cache
set，然后在prime和probe阶段只监控这些cache set，而不是监控整个LLC。

##### 5.1.1.1.3 定位victim cache set
如何定位与victim中那些安全关键访问相关的cache set仍是个不小的挑战。这是因为攻击
者并不知道victim中那些安全关键访问的虚拟地址，并且也完全无法控制如何将这些虚拟地
址映射到物理地址。

解决方案之一是通过每次监控一个cache set，来扫描整个LLC，并从中寻找与安全关键访问
在时间上同步的内存访问模式。

注意：这种内存访问模式与victim所使用的算法直接相关。因此，从本质上说，边信道攻击
与被攻击对象的具体细节息息相关。

##### 5.1.1.1.4 构造eviction set
在不知道地址映射的前提下，如何构造一个恰好填满一个cache set的eviction set呢？这
个问题可以通过使用large page / 大容量页来解决。为了我们的目的，large page消除了
分析虚拟地址到物理映射的必要：2MB的页容量就足够大了，因为所有的index位
（6位...16位)都被包含在页内地址位中（0位...20位），因此所有的index位将在物理地址
中得以保留。

对于现代的Intel CPU，large page是不足以定位一个LLC的slice的，因为index相同的
memory line可能被存放在不同的slice中。因此，不能直接构造某个slice中的某个cache
set的eviction set，相反我们首先构造一个包含所有slice中这个特定cache set的
conflict set，其中每个cache set中恰好有w个cache line，然后再把这个conflict
set按照slice分割成若干eviction set：

1. 申请一个缓冲（事先启用large page），容量至少是LLC的2倍；
   注意：不是十分理解为什么至少需要2倍于LLC的容量。问过论文的作者，但是没有得到
   答复。我的理解是，此处其实并非需要2倍于LLC的容量，但是对于后面的分区操作确实
   必须的，因为每个cache set至少需要发生一次冲突；

1. 从这个缓冲中，选择出一组可能冲突的memory line，即
   index位（6位...16位）相同的memory line；

1. 最初conflict set和eviction set都为空；

1. 对于选出的memory line中的每一个候选者，如果它不与conflict
   set中的任何一个memory line冲突，则把它加入conflict set；

    1. 为了检测冲突，首先读取候选者，把它载入cache，然后再把conflict set载入
       cache，最后再次读取候选者并检测所花费的时间。短时间暗示缓存命中，长时间暗
       示冲突；

1. 现在conflict set包含了所有slice中的某个cache set，并且每个cache set中恰好有w
   个cache line；

1. 为了对conflict set分区，首先从那些没有成功加入conflict set的memory
   line中选取一个候选者；然后对conflict set中的成员进行遍历，如果删除这个成员以
   后这个候选者不再与conflict set冲突，则这个成员与当前候选者属于同一个slice。通
   过遍历conflict set中的所有成员，可以找到所有与当前候选者属于同一个slice的成员
   ，也就构造出了一个slice的evictin set；

1. 通过遍历所有的候选者，可以把conflict set分割成与每个slice对应的eviction set。

为所有可能的cache set index（共2,048个）重复以上算法，可以构造出包含所有cache
set的eviction set。

##### 5.1.1.1.5 Probe分辨率
LLC的Probe分辨率可以通过测量基于LLC的隐蔽信道的容量来描述：

发送方：
1. 发送方与接收方都申请一个缓冲，至少与LLC容量相同，并启用large page；

1. 发送发从缓冲中选择两个memory line，line 0与line 1，分别映射到两个实现约定好的
   cache set。如果要发送“1”，发送发持续访问一段时间的line 1；同理，访问line 0来
   发送“0”。

接收方：
1. 在监控发送方之前，接收方首先为line 0和line 1创建eviction set0和eviction set 1
   ；

1. 然后通过Prime + Probe来持续监控两个cache set。

#### 5.1.1.2 示例
考虑下面的代码：
```c
// data is a secrete array consisting of 0 and 1.
data = {0, 1, 0, ... };

for (i in data) {

    // do operation 1;
    if ( i == 1 ) {
        // do operation 2;
    }

}
```

当处理“1”的时候，opeartion 1被执行，随后执行operation 2。反之，如果处理“0”，
operation 1被执行，随后下一个opeartion 1被执行。因此，通过观察operation 1之间的
时间间隔就可以获取data的内容。

具体的Prime + Probe的攻击步骤如下：
1. 为每个cache set创建evication set；

1. 定位包含operation 1代码的cache set：

    1. 为了追踪一个cache set，首先把时间分割成包含足够多时钟周期
       （如：5,000个时钟周期）的片段，这应该足够短了，从而可以在一个循环中probe
       多次；

    1. 在每个时间片中，prime这个cache set，等待直到时间片结束，然后probe这个
       cache set；

    1. 通过对每个cache set使用Prime + Probe监控足够长的时间（如：1,000个时间片）
       ,可以发现有一些cache set几乎总是被访问，而有一些则只是偶尔被访问；但是应
       该有一个cache set（如：cache set #43），它展示了我们期望在operation 1上看
       到的活动模式，因此我们可以断定operation 1的代码存储在这个cache set中；

1. 对这个cache set进行Prime + Probe，两次冲突之间的时间间隔可以用来获取data的内
   容：短间隔表示“0”，长间隔表示“1”。

### 5.1.2 Prime + Abort
Prime + Abort攻击 [[50]] 与Prime + Probe攻击类似，但是与后者相比有两个优点：

第一点是Prime + Abort依靠TSX的事务来检测缓存冲突，因此不需要任何形式的timer：

1. 开始一个事务；

1. 通过加载eviction set来prime一个cache set

1. 同时，如果victim的代码从cache set中淘汰任何cache line，则发生冲突，事务因而被
   终止，攻击者代码中的abort handler被触发。

第二点是攻击的效率。TSX的硬件允许victim的活动直接触发攻击者的进程采取行动。这意
味着TSX攻击可以跳过传统攻击中的检测阶段。

### 5.1.3 Flush + Reload
Flush + Reload [[49]] 是一种缓存边信道攻击技术，它利用Intel X86 CPU缺少对使用
clflush指令的限制这一事实来监控对共享内存页的访问。它是Prime + Probe的一个变种，
需要依靠间谍进程与victim进程之间的共享内存页。

攻击者A运行间谍进程来监控victim进程V对内存的使用：

间谍进程与victim进程共享一个物理页：间谍进程通过mmaps()函数将victim的可执行文件
映射到间谍进程的虚拟地址空间。

注意：现在victim的可执行文件被映射到了间谍进程的虚拟地址空间中的某个虚拟地址上，
因此间谍软件可以对被映射区域内的任何字节进行寻址并读取。

当一个页被共享时，页中的所有memory line在共享进程的虚拟地址空间内被映射到与原始
进程中相同的物理地址。因为LLC是基于物理地址寻址的，缓存中的cache line只依赖于共
享页的物理地址，而与页所映射到的进程的虚拟地址无关。因而，我们不需要关注虚拟地址
到物理地址的映射。

在开始攻击之前，攻击者必须确定应该监控哪些memory line，步骤如下：

1. 阅读并理解victim进程的源代码，选择一些重度依赖于我们将要监控活动的函数；

1. 如果victim的可执行文件包含debug symbols，这些symbol可以用来将源代码中的代码行
   映射到虚拟地址；

1. 如果，victim的可执行文件不包含debug symbol，可以通过逆向工程来恢复这种映射，
   但这超出了本文的讨论范围；

1. 这些memory line在间谍进程中的虚拟地址可以这样计算：
   virtual-address = base-in-spy + offset-in-victim

在攻击的第一阶段，间谍进程通过clflush指令将那些被监控的memory line淘汰出缓存。

注意：clflush()函数从缓存中淘汰指定的memory line（基于虚拟地址）。

在攻击的第二阶段，间谍进程等待victim进程访问这些memory line。

在第三阶段，间谍进程reload / 重新载入这些memory line并测量访问时间。如果在第二阶
段，victim进程访问了这些memory line，那么此时这些memory line就已经被缓存了，
reload将会花费短暂的时间。如果，victim没有访问这些memory line，这些memory line需
要从内存载入，因而reload会明显花费更长的时间。

#### 5.1.3.1 示例
考虑以下代码：
```c
// data is a secrete array consisting of 0 and 1.
data = {0, 1, 0, ... };

for (i in data) {

    // do operation 1;
    if ( i == 1 ) {
        // do operation 2;
    }

}
```
Flush + Reload攻击的步骤如下：
1. 间谍进程通过mmaps()函数将victim进程的可执行文件映射到间谍进程的虚拟地址空间；

1. 将时间分割成包含足够多时钟周期的时间片（如：2,500个时钟周期），这应该足够短，
   从而可以在一个循环中获得多次probe；

1. 在每个时间片内，间谍进程flush包含operation 1代码的memory line，然后等待到时间
   片结束；

1. 间谍进程probe被监控的memory line：短暂的载入时间意味着缓存命中（victim进程执
   行了operation 1），比较长的载入时间意味着缓存未命中；

1. 两次缓存命中之间的时间间隔可以用来获取data的内容：短暂的间隔意味着“0”，长的间
   隔意味着“1”。

### 5.1.4 Evict + Time
Evict + Time 攻击[[56]] 的步骤如下：
1. Evict: 攻击者用自己的数据填充某一个cache set（从而清除之前的数据）；
1. Time：攻击者触发victim进程执行某些安全相关的操作（如：对一段文本加密）并测量
   执行时间；

如果victim之前在这个cache set中有缓存数据，并且本次操作需要访问这些数据，那么本
次执行时间会比它不需要访问这些数据的情况下要长。换言之，如果当前的cache set与
victim无关，那么执行时间会比较短，因为victim可以从相关cache set中读取缓存数据，
反之，如果当前cache set与victim相关，因为Evict阶段已经将cache set的数据清空，所
以相应的执行时间会比较长。攻击者通过枚举不同的cache set，可以最终确定那些与
victim相关的cache set。

### 5.1.5 Meltdown
根据我们在内存隔离章节所讨论的，内核空间可以映射到整个物理内存，并且通常会被映射
到每个用户进程的地址空间中。

在现代CPU的架构中，乱序执行是一种用以解决执行单元闲置的重要性能特性。然而，我们
观察到在某些CPU中，被乱序执行的用户进程可以把内核空间或物理空间的数据读取到CPU的
寄存器中。此外，CPU还可以基于这些数据做进一步的计算，例如，将寄存器中的值作为起
始地址访问数组。我们还发现乱序执行的内存访问会影响缓存，其效果可以通过缓存边信
道攻击被侦测到。我们称那种被乱序执行并留下可侦测副作用的指令为“临时指令”，称包含
至少一条临时指令的指令序列为“临时指令序列”。

Meltdown [[43]] 利用了以上的事实读取内核空间的任何地址，包括个人信息与密码，甚至
可以导出整个内核空间。

#### 5.1.5.1 示例
Meltdown攻击有三个步骤：

1. 将攻击者选择的内核地址的内容载入寄存器，这毫无疑问会触发例外，因为这个地址是
   不允许用户进程访问的；

2. 在例外被抛出之前，一条临时指令访问一个cache line，cache line的地址是基于寄
   存器中存储的秘密内容计算的来的；

3. 在例外处理程序中，攻击者通过Flush + Reload攻击确定被访问的cache line，从而进
   一步确定存储在内核地址的内容。

Meltdown攻击的核心代码如下：
```asm
1 mov rcx, <内核地址>
2 mov rbx, <probe数组的起始地址>
3 mov al, byte [rcx] 
4 shl rax, 0xc 
5 mov rbx, qword [rbx + rax]
```

我们将会逐行分析这段代码。

* 第1步：读取秘密
    * 第1行，攻击者选择的内核地址被载入寄存器rcx；
    * 第2行，probe数组的起始地址被载入寄存器rbx；
    * 第3行，尝试将存储在内核地址上的一个字节的数据载入寄存器rax的低8位子寄存
      器，也被称为al；要将数据从内存载入寄存器，需要使用虚拟地址。按照之前的
      讨论，现代操作系统总是将整个内核地址空间映射到每个用户进程的地址空间。因而
      ，在用户进程的虚拟地址空间，任何内核地址都可以被映射到一个合法的物理地址，
      并且CPU会先去访问上述地址，只不过此处CPU会抛出例外，因为用户进程没有访问上
      述地址的权限；
   
* 第2步：传输秘密
    * 在第3行代码抛出例外与后继指令的乱序执行之间，存在“竞争条件”，因而在例外
      被抛出之前，存在一个很短暂的时间窗口，在这段时间内CPU仍然会以乱序方式执行
      后继指令；
    * 第4行，基于第1步读取的秘密，计算probe array中某个字节的索引：
      rax = rax * 4096（其中：4,096 = 0xC）；
      根据prefetcher章节的讨论，prefetcher不能跨跃4KB范围，此处的4096（4KB）可以
      避免prefetcher将临近的memory line预取到缓存中；此处，我们每次只读取一个字
      节的秘密，因而probe array的容量为256 * 4096个Bytes（可以理解为probe array
      有256个memory页，每个页的容量为4KB）。

* 第3步：获取秘密
    * 在第3步，例外最终被抛出，攻击者在例外处理程序中通过缓存边信道攻击获取秘密
      数据；当第2步的临时指令被乱序执行时，probe array中的一个字节所在的
      memory line被缓存，而这个被缓存的memory line在probe array中的位置只与第1步
      中读取的这个秘密有关。因而，攻击者只要遍历probe array中的256个页，并测量访
      问每个页中第一个memory line（probe-array[n * 4096]）的时间，就可以确定秘密
      的值：被缓存的memory line所在页的编号即为秘密；
       
通过对不同的内核地址重复以上三个步骤，攻击者可以导出整个内核地址空间。因为主要的
操作系统通常将整个内核空间映射到每个用户进程的虚拟地址空间，且内核空间可以映射整
个物理内存，所以Meltdown不仅可以读取内核的内容，也可以读取整个物理内存的内容。

#### 5.1.5.2 优化与限制

##### 5.1.5.2.1 关于0
当用户进程试图读取无权访问的内核地址时，CPU会抛出例外，随后相应的寄存器会被清零
。这是很合理的，因为如果例外没有被处理，用户的程序会异常退出，而存储在寄存器中的
秘密会被保存在因异常退出而产生的dump文件中，从而泄密。而要解决这个问题，最直接的
方法就是将对应的寄存器清零。如果对寄存器清零的操作比乱序执行的指令快
（本例中的第4行），那么攻击者有可能在第3步读取到错误的值。

为了防止临时指令序列读取到错误的值，例如“0”，代码可以做如下调整：
```asm
1 mov rcx, <内核地址>
2 mov rbx, <probe数组的起始地址>
3 retry:
4 mov al, byte [rcx] 
5 shl rax, 0xc
6 jz retry
7 mov rbx, qword [rbx + rax]
```

Meltdown攻击不断尝试读取内核地址，直到读取到一个非“0”的值（第6行），或等例外最终
被抛出。例外抛出后，临时指令序列会被终止，因此如果秘密的值确实是“0”，则
probe-array[0]不会被缓存。

##### 5.2.5.2.2 传输单比特位
Meltdown攻击每次通过隐蔽信道传输8个比特位，并且需要执行256（2⁸）次Flush + Reload
攻击来读取秘密。而Meltdown攻击的性能瓶颈其实是在Flush + Reload阶段。通过调整算法
，每次只传输一个比特位，我们可以将Flush + Reload的次数降为1次，即对memory line 1
的观测（因为memory line 0总是不被缓存的）。如果比特位为“1”，则memory line 1被缓
存，否则memory line 1不被缓存。

##### 5.2.5.2.3 通过Intel TSX抑制例外
Intel TSX可以将多个指令放在一个事务中，形成原子操作，换言之，所有的指令要么全部
成功，要么全部失败。如果事务中的某条指令失败，所有已经执行的指令会被撤销，但是不
会抛出例外。如果我们将示例代码放入一个事务中，则可以消除例外。

##### 5.2.5.2.4 应对KASLR
KASLR可以通过Dkr来破解。

#### 5.2.5.3 评估
Meltdown在一些ARM与AMD CPU上做过测试，但是到目前为止还没有在这些处理器上成功重现
上述攻击。但是这不意味着这些CPU对这类攻击一定免疫，因为我们观察到乱序执行在这些
CPU上同样会执行非法的内存访问。

#### 5.2.5.4 应对措施

##### 5.2.5.4.1 硬件
因为Meltdown利用了乱序执行，一种简单粗暴的应对措施是彻底禁用乱序执行。然而，由此
产生的性能问题将会是毁灭性的，因为现代CPU的并行性将彻底失效。因而，这不是一个可
行的解决方案。

Meltdown是介于内存读取与权限检查之间的某种竞争条件，因此将权限检查与内存读取串行
化可以防止Meltdown。但这会显著增加每次内存读取的开销，因为内存读取必须等权限检查
结束以后才可能发生。

一种更现实的解决方案是在硬件层面引入用户空间与内核空间的隔离。这可以通过CPU控制
寄存器中的一个用于控制分割的比特位来启用，并由现代操作系统选择是否支持。如果这个
比特位被设置，内核必须载入上部空间，而用户进程必须载入下部空间。通过这个硬件级别
的隔离手段，一个内存访问可以立刻确定是否违反权限策略，因为权限级别可以直接从虚拟
地址段来确定，而毋需进一步的查询。我们预计这个解决方案对性能的影响是可以忽略的。

##### 5.2.5.4.2 KAISER
因为硬件没有那么容易实施补丁，在新的硬件就绪之前，软件的临时解决方案就很有必要了
。KAISER，一种对操作系统内核的修改，不再将整个内核空间映射到用户空间，可以防止
Meltdown，因为它确保用户进程无法对内核空间寻址。目前KAISER是最好的短期解决方案，
因此应该立刻在所有系统上启用。

#### 5.2.5.5 结论
在论文中，作者介绍了Meltdown，一种可以利用现代处理器中的乱序执行在用户空间的应用
程序中读取任意位置的内核地址或物理内存，全新的基于软件的边信道攻击方式。不需要任
何软件的缺陷，并且与操作系统无关，Meltdown允许攻击者在云计算环境中以最高503KB/s
的速度读取其它进程或者虚拟机中的私密信息，影响数以百万计的设备。作者演示了KAISER
，一种最初用于防止针对KASLR的边信道攻击的技术，也可以防止Meltdown。作者强调，为
了防止大规模的Meltdown攻击，作为短期解决方案，KAISER需要被部署到每一个操作系统中
，直到Meltdown在硬件层面被修复。

### 5.2.6 Spectre
根据我们之前的讨论，speculative execution / 预测执行是一种高速CPU通过猜测程序未
来的执行路径并预执行指令来提高性能的技术。

粗略地讲，Spectre攻击 [[44]] 通过联合使用预测执行与隐蔽信道来突破内存隔离的界限
。更确切地讲，为了发起Spectre攻击，攻击者首先在victim进程的地址空间中寻找一个指
令序列，当这些指令被执行的时候，它们将充当隐蔽信道的传信者，并通过隐蔽信道向外泄
露内存或寄存器的内容；攻击者接着将“欺骗”CPU，令其错误地预测执行被选中的指令序列
，进而通过隐蔽信道泄露信息；最后，攻击者通过隐蔽信道获取被泄露的信息。

注意：尽管最终当CPU明白自己“被骗”以后，之前预测执行所造成的对CPU状态的改变最终会
被撤销，但是对缓存状态的改变却被保留了下来，这是构造隐蔽信道的基础。

#### 5.2.6.1 技术细节
有两种类型的Spectre：conditional branches based / 基于条件分支的攻击，与indirect
branches based / 基于间接分支的攻击。

##### 5.2.6.1.1 利用条件分支
为了利用条件分支，攻击者需要训练branch predictor错误地预测分支的跳转，进而导致处
理器预测执行那些正常情况下不会被执行的指令，从而泄露信息。参照如下的代码：
```c
if ( x < array1_size) {
    y = array2[array1[x] * 256];
}
```
注意：此处的跨度为256个字节（地址的低8位是相同的），因而IP prefetcher不会工作，
所以L2 Streamer也不会被触发，所以，其实并不需要4,096个字节的跨度。

在这个例子中，变量x保存着攻击者提供的数据。if分支被编译为一个条件分支，它的
目的是确保x的值在合理的范围内，从而保证对array1数组的访问是合法的。

为了发起攻击，攻击者首先用合法的x调用这段代码来训练branch predictor令其错误地预
测if语句为true；攻击者接着用一个越界的x调用这段代码，并保证``array1_size``
不被缓存；CPU因为猜测条件分支为true，所以会使用这个越界的x值来预执行从
array2[array1[x] * 256]读取数据的操作；对array2的读取操作会将地址依赖于array1[x]
的数据载入缓存；当CPU意识到预测执行是错误的时候，缓存状态的变化不会被撤销，并且
可以被攻击者侦测到并进一步获取victim内存中的一个字节的数据。

注：x的值可以是正值或负值，通过调整不同的x的值，array1[x]可以定位到victim
地址空间中的任何一个字节。

##### 5.2.6.1.2 利用间接分支
对于间接分支，攻击者首先从victim的地址空间中选择一段代码（称为gadget）并影响
victim使其预测执行这个gadget。攻击者通过训练Branch Target Buffer（BTB）令其错误
地预测一条间接分支指令的目标到这个gadget的地址，进而导致gadget被预测执行。当被预
测执行的指令最终被终止，它们对缓存造成的影响不会被撤销。这些影响可以被gadget利用
来泄露敏感信息。通过仔细选择gadget，这种方法可以被用来读取victim空间的任意位置的
内存。

为了训练BTB，攻击者在victim的地址空间中寻找gadget，并确定gadget的地址，随后执行
跳转到这个地址的间接分支。这种训练是在攻击者地址空间中执行的，并且在攻击者的地址
空间内这个gadget地址中的内容是无关紧要的；攻击者只需要保证用于训练BTB的间接分支
是跳转到这个虚拟地址的（实际上，只要攻击者进程可以捕捉例外，在攻击者进程的地址空
间中，gadget虚拟地址上甚至可以没有任何代码）。此外，用于训练BTB的间接分支的地址
也不必与victim中的间接分支的地址相同。因此，攻击者对于建立这种训练有非常大的灵活
度。

#### 5.2.6.2 与Meltdown的区别
首先，不同于Spectre，Meltdown不使用分支预测来触发乱序执行，而是依靠引起例外的指
令触发其后继指令的乱序执行。其次，Meltdown利用一个Intel CPU的权限控制的缺陷，从
而令乱序执行的指令跳过内存权限检查。

Meltdown首先造成一个例外，但是在这个例外被抛出之前，其后继代码可以通过隐蔽信道泄
露被访问的内存的内容。与Meltdown不同，Spectre攻击对非Intel的CPU，包括AMD和ARM，
也有效。此外，作为针对Meltdown的系统补丁，KAISER已经被广泛应用，但它却不能防止
Spectre，因为Spectre利用victim的代码攻击victim的地址空间，所以它不需要跳过内存权
限检查，但是在某些情况下，它确实需要依靠预测执行的指令来跳过数组的越界检查。

#### 5.2.6.3 概述
大多数情况下，Spectre攻击由一个设置阶段开始，攻击者在这个阶段执行一些操作来训练
处理器，从而令CPU做出可以被利用的错误的预测。此外，设置阶段通常包括帮助引起预测
执行的步骤，例如读取特定地址的内存从而令CPU从缓存中淘汰一个对确定分支指令的目标
必须的值。在设置阶段攻击者也可以准备用于获取victim信息的边信道，例如执行
Flush + Reload中的Flush操作。

在第二个阶段，被CPU预测执行的指令把私密信息从vicitm的空间传输到隐蔽信道。还有一
种情况，攻击者可以利用自身的预测执行代码来获取存在于它所在进程中的私密信息
（例如，如果攻击者代码存在于解释器、或者JIT编译器的sandbox中，或者是某种“安全”的
语言，而攻击者代码试图读取本来无权访问的内存）。

在最后阶段，私密信息被获取。基于Flush + Reload方式的Spectre攻击是通过测量读取被
监控cache line所花费的时间长短来取私密信息的。

Spectre攻击只基于一个前提条件：被预测执行指令可以读取那些victim进程正常情况下可
以读取的内存（例如：不会触发页错误，或例外）。所以，即使CPU不允许用户进程中的预
测执行指令访问内核空间，Spectre仍然有效。因此，Spectre比Meltdown的使用范围更广，
因为后者需要利用用户空间的乱序执行来访问内核空间。

##### 5.2.6.3.1 利用条件分支
假设下面的代码是一个函数的一部分（例如内核的syscall或加密库），它从不可信的来源
（可能来自攻击者）接受一个unsigned int类型的变量x。运行这段代码的进程可以访问一
个由unsigned byte类型组成的数组array1，其长度为``array1_size``，以及另外一个
unsigned byte数组aray2，其长度为64K（64K = 256 * 256）。
```c
if (x < array1_size) {
    y = array2[array1[x] * 256];
}
```

出于基本的安全考虑，这段代码首先检查x的范围。在此处，这个检查可以防止CPU越界读取
敏感信息。否则，一个越界的x会触发例外，或者导致CPU访问特定位置的敏感信息（如果
x = 敏感信息的地址 - ``array1``的起始地址）。

不幸的是，通过预测执行，此处的条件分支可能会沿着错误的路径执行下去。例如，假设攻
击者导致代码运行如下：
* x的值被恶意设计，从而array1[x]指向victim空间中某个秘密的字节k；

* ``array1_size``与array2没有被缓存，但是k已经被缓存；

* 之前的操作接受的都是合法的x，导致branch predictor错误地预测if语句的结果为true
  ；

此处所需要的缓存状态可以自然发生，也可以由攻击者创造，例如通过读取大量内存无关的
数据将缓存填满，接着让内核通过一种合法的手段使用一次私密信息。如果事先了解缓存的
结构（物理内存到slice id的hash函数）或如果CPU支持flush指令（例如clflush），那么
可以更有效地达到所需要的缓存状态。

当上述代码被编译并执行的时候，处理器首先将恶意的x与``array1_size``比较。
``array1_size``没有被缓存，需要从内存中读取它的值，在此之前CPU面临大量的延迟。在
这段时间内，branch predictor错误地预测if语句的结果为true，于是开始预测执行后继的
逻辑。因为array1[x]指向那个被缓存的私密信息字节k，读取array1[x]直接返回k。预测执
行继续计算array2[k * 256]的地址，并试图读取它的内容（导致另一个cache miss）。在
等待array2的数据的时候，``array1_size``的值从内存载入寄存器。CPU意识到预测执行是
错误的，于是恢复寄存器状态。但是，在实际的CPU中，从array2的读取数据的预测执行指
令已经对缓存的状态造成了与地址相关的影响，而这个地址与k直接相关。

为了完成攻击，攻击者只需要通过侦测缓存状态的变化来获取k的值。如果攻击者可以访问
array2（例如，攻击者进程存在于解释器的sandbox中），这会非常容易，因为对
array2[n * 256]的读取时间会有差别，如果n=k，读取时间短，否则时间长。如果攻击者不
能访问array2，可以通过Prime + Probe攻击来推断k的值，但是根据我的理解，这需要做以
下调整：

* 启用large page size （2MB）；

* 我们需要确定array2在victim地址空间的中的起始虚拟地址，并在攻击者进程的地址空间
  中在相同的地址申请一个buffer数组，因而buffer[k * 256]与array2[k * 256]的虚拟地
  址是相同的，因此cache set index也相同（但不能保证两者的slice id相同）。

Prime + Probe的步骤如下：
1. 攻击者为每个buffer[k * 256]构造eviction set，其中k的范围为[0,
   255]；对每个k，eviction set包括所有的slice，每个slice中有w个cache line；

   注意：因为所有buffer[k * 256]的第6位到第16位的地址都是不同的，因而它们属于不
   同的cache set，不会发生cache set重叠的情况。

1. 在Prime阶段，对每个k，攻击者尝试载入它的eviction set（所有slice中的cache
   line），然后等待；

1. 在Probe阶段，对每个k，攻击者尝试载入它的eviction
   set，并测量访问时间。如果对于某个k，载入时间明显比较长，则说明array2[k * 256]
   被victim的代码载入（因而淘汰了eviction set中的某个cache line）；

注意：对于当前cache set index，有必要载入所有slice中的cache line，这是因为
buffer[k * 256]与array2[k * 256]可能存在于不同的slice，尽管它们的cache set index
相同。 

###### 5.2.6.3.1.1 JavaScript示例
在本章节一段JavaScript代码被用来作为概念验证，当在Chrome浏览器中运行它时，它可以
从运行它的进程中读取私有数据。用于泄露私密信息的代码片段如下，其中
``TABLE1_STRIDE``=4096（防止预取），``TABLE_BYTES``=2²⁵：

```javascript
if (index < simpleByteArray.length) {
    index = simpleByteArray[index | 0];
    index = index * TABLE1_STRIDE|0;
    index = index & (TABLE1_BYTES - 1);
    index = index | 0;
    localJunk ^= probeTable[index|0]|0;
}
```

在branch predictor的训练阶段，index被设置为合法的值，再最后一次执行的时候，index
被设置为一个越界值。变量localJunk的作用是确保无用操作不会被解释器为了优化而删除
，“|0”操作的作用是提示JavaScript解释器这是一个数字。

与其它优化的JavaScript引擎一样，V8通过just-in-time编译将JavaScript编译成为机器语
言。可以使用D8命令行工具获得对应的x86汇编语言代码。通过手动调整源代码，可以产生
如下的汇编代码，其中simpleByteArray.length的值需要使用一条指令从内存中获得（而不
是被缓存在寄存器中，或需要多条指令获取）。

```asm
1: cmpl r15, [rbp-0xe0]

2: jnc 0x24dd099bb870

3: REX.W leaq rsi, [r12+rdx*1]

4: movzxbl rsi, [rsi+r15*1]

5: shll rsi, 12

6: andl rsi, 0x1ffffff

7: movzxbl rsi, [rsi+r8*1]

8: xorl rsi, rdi

9: REX.W movq rdi, rsi 
```
代码的解释如下：
1. 将index的值与simpleByteArray.length比较。其中，index的值保存在r15寄存器中，而
   rbp寄存器的值是当前栈的起始地址，并且simpleByteArray.length被保存在当前栈以下
   0xe0（224）个字节的位置（栈空间是向下扩展的）;

1. 如果index >= simpleByteArray.length，跳转到地址0x24dd099bb870，这个地址应该位
   于第9行以后的某个位置；

1. rsi = r12 + rdx，现在rsi寄存器的值为simpleByteArray中第一个字节的地址，即
   base-address；

1. 从base-address + index这个地址读取一个字节，并将字节的内容存入rsi寄存器；

1. rsi = rsi * 4096（向左移动12位）；

1. 将0x1ffffff（25位）作为mask与rsi的值进行逻辑与操作，以此保证rsi的值不越界；

1. rsi = probeTable[index] ，其中r8寄存器的值为probeTable的base-address；

1. rsi = rsi XOR localJunk，其中rdi寄存器保存着localJunk的值；

1. localJunk = rsi。

JavaScript中不能调用clflush指令，因此清除缓存的动作是通过读取一个大数组中一系列
地址间隔为4,096个字节的数据来完成的。因为Intel CPU的内存与缓存的配置，大约读取
2,000（具体数字取决于缓存的容量）条左右这样的数据就足以将所有第6-11位地址相同的
数据从缓存中清除（因为地址的第12-16位不确定，因此有32种可能，再乘以核心的数量，
再乘以路数w）：
no-of-lines = core * w * 32（这个算法是我猜测的，论文中并没有提及，并且论文中也
没有提及2,000条这个数字是如何得来的）。

注意：因为地址的跨度为4,096个字节，因此地址的第0-11位总是相同的。

泄露的数据通过probeTable[n * 4096]来传输，其中n的范围为[0, 255]，因此每一次攻击
由读取一系列probeTable[n * 4096]数据开始，其中n >= 256。根据我们之前的讨论，某些
CPU使用自适应的缓存淘汰策略，为了训练CPU使用LRU策略，每次读取
probeTable[n * 4096]以后，再访问它几次，然后再读取probeTable[ (n+1) * 4096 ]，因
为CPU会认为probeTable[n * 4096]在被淘汰之前曾被反复访问，因此会选择LRU策略。

JavaScript不能访问rdtscp指令，并且Chrome特地降低了它的高分辨率timer的精确度以应
对通过使用performance.now()来发起的时间攻击。但是，利用HTML5中的Web Worker可以很
容易地创建一个线程，这个线程可以反复地减少一个位于共享内存的变量的值。

##### 5.2.6.3.2 利用间接跳转
间接分支指令可以跳转到两个以上的目标地址。例如，x86的指令可以跳转到一个寄存器中
保存的地址（“jmp exa”），内存中保存的地址
（“jmp [exa]”，或“jmp dword ptr [0x12345678]”），或保存在栈内的地址（“ret”）。其
它CPU也支持间接分支指令，如ARM（如“MOV pc, r14”）、MIPS（如“jr $ra”）、RISC-V
（如“jalr x0, x1, 0”）等等。

如果因为缓存未命中导致确定跳转地址被延迟，并且branch predictor被训练跳转到恶意地
址（虚拟地址），那么CPU将会在攻击者选择的地址启动预测执行。因此，预测执行可以被
导向正常情况下永远都不会到达的位置。如果预测执行可以留下可观测的副作用，对于攻击
者来说，这将成为极其强大的攻击手段，例如即使没有可以被利用的条件分支，也可以读取
victim内存的内容。

想象这样一个场景，当间接分支被执行的时候，意图读取victim内存的攻击者可以控制两个
寄存器中的值（表示为R1和R2）。这是一个很普遍的场景：从外界接受参数的函数正常执行
代码，同时寄存器中保存着攻击者可以控制的值（通常，这些值被函数忽略；在调用开始时
寄存器的值被压入堆栈，在调用结束时寄存器的值从堆栈恢复）。

假定CPU限制预测执行只能在victim进程有执行权限的内存区域执行，则攻击者只能在
victim的代码中寻找gadget，并且这个gadget运行之后会泄露指定地址的内容。例如，这样
的一个gadget可能由两条指令组成（它们并不需要彼此相邻），其中第一条指令读取R1的值
，把它作为一个地址，将这个地址中的数值与R2中的数值进行某种运算（加法、减法、乘法
、XOR等等），第二条指令读取R2的值，也把它作为一个地址，并读取这个地址的值。在这
个例子中，gadget允许攻击者控制泄露内容的地址（R1），以及如何将泄露的内容映射到另
外一个内存地址（R2），这个地址将会被第二条指令读取（后面章节中Windows上的例子详
细讨论了这种gadget的读取流程）。

###### 5.2.6.3.2.1 讨论
研究者们观察到了若干相关的硬件与操作系统的事实，包括：

* 在Hashwell处理器上一个超线程的代码可以训练并影响另一个运行于同一个CPU核心上的
  超线程的branch predictor。在Skylake处理器上的测试进一步证实运行于同一个vCPU
  （虚拟机CPU）上的进程之间可以训练彼此的BTB；

* 只有当victim对间接分支的目标地址有执行权限，预测执行才会发生，因此gadget需要在
  victim的可执行内存区域寻找；

* 当多个Windows应用程序共享一个DLL的时候，通常只有一份DLL被载入物理内存（除非内
  存页被修改，稍后会讨论），并且在所有调用这个DLL的进程中，这个DLL的虚拟地址都是
  相同的。即使在一个最简单的Windows应用中，因为它调用了某个DLL，DLL页就会被映射
  到它的地址空间，DLL的可执行页通常包含几兆的代码，这提供了足够大的可以用来寻找
  gadget的空间；

* 对于历史纪录匹配与目标预测，branch predictor似乎只关心分支目标的虚拟地址。执行
  跳转的指令所在的虚拟地址、物理地址、时间、以及进程号似乎都无关紧要；对于这一段
  叙述不是十分理解：此处，如果作者所描述的branch predictor是指判断分支是否被
  taken的硬件，那么根据 [[30]] 中的描述，branch predictor应该不涉及分支的目标
  地址，这不符合本段描述；如果作者指的是BTB，那么按照前面的叙述，BTB会使用指令原
  始地址中最低的20位作为address tag，并保存完整的目标虚拟地址，这也于本段描述不
  符；

* 用来追踪和匹配跳转历史的算法似乎只使用低段的地址位（这被hash函数进一步的简化）
  ，因此分支指令所在的虚拟地址并不十分重要。所以，如果victim的分支指令的虚拟地址
  为A，在攻击者自己的地址空间中，它甚至不需要对自己的虚拟地址A有执行权限，却仍然
  可以训练branch predictor与BTB。ASLR的效果也可以被抵消，因为算法忽略高段地址位
  ，而第0位到15位的地址不会被随机化；这一段大概是说branch predictor [[30]] 只用
  到分支指令虚拟地址中的低段地址位，BTB的address tag只会用到分支指令虚拟地址中最
  低的20位 [[44]]。 

* 攻击者通过跳转到非法目标地址来训练BTB。尽管在攻击者的进程中，例外会被触发，但
  例外可以被捕捉（例如，通过try...catch）。随后BTB将会把其它进程导向这个非法地址
  ；

* 跨CPU的分支训练并没有被观察到，说明每个CPU上的BTB是彼此独立工作的；

* DLL的代码页与常量页可以被任何调用DLL的进程通过clflush指令清除，使他们很容易被
  用作Flush + Reload攻击中的表空间；

* DLL区域可以被应用程序修改。此时会用到copy-on-write机制，从而令这些修改只对修改
  者可见。这进一步简化了BTB的训练，因为这允许gadget在训练过程中干净地返回，而不
  管有什么指令跟在gadget之后（攻击者可以修改DLL区域的代码，让训练用的gadget直接
  返回）；

* 尽管测试使用32位的应用程序，基于64位模式运行在Windows 8系统上，其它版本的
  Windows以及Linux的共享库的工作方式很可能是类似的。内核模式还没有被测试，但是根
  据跳转历史匹配算法对源地址的截取与hash，以及可以通过跳转至非法地址对BTB进行训
  练这些事实，可以推测对内核模式的攻击也是可能的。这种攻击方式对其它方式的跳转，
  如中断、中断返回的影响仍然是未知的。

###### 5.2.6.3.2.2 Windows上的例子
作为概念验证，研究者开发了这样一个简单的Windows程序：它首先生成一个随机的key，随
后执行一个无限循环，在循环中调用Sleep(0)来短暂停止，读入一个文件中的一些前导字节
（如文件头），调用Windows的crypto函数计算key或者文件头的SHA-1 hash，并在文件头被
修改的时候打印hash。当编译这个程序的时候，如果启用优化选项，调用Sleep()函数的时
候，文件的数据会被保存在ebx寄存器与edi寄存器中。如我们之前讨论的，当函数被调用的
时候，寄存器中存储着攻击者可以控制的值是很常见的（实际上我们可以通过修改文件内容
来随意控制这两个寄存器的值），尽管具体的细节（如，什么值保存在哪个寄存器中）通常
由编译器的优化算法决定，因此很难从源代码中预测。测试程序不包含任何内存清除操作或
其它帮助攻击者的调整。

攻击的第一步是找到一个gadget，当预测执行它的时候，攻击者可以控制的值被存在在寄存
器ebx和寄存器edi中，它会泄露victim进程中由攻击者指定地址的内存中的内容。根据之前
的讨论，这个gadget必须存在于victim的可执行页中。（在Windows中，DLL中的一些页被映
射到用户进程的地址空间的时候会触发一个soft page fault）。为了寻找这样的gadget，
可以写一个最简单的程序，并将它的内存页保存为一个文件，因为这个程序调用了DLL，它
的内存页的大部分内容代表了所有应用程序内存页的共同内容。随后可以在这个文件中寻找
可用的gadget，并找到多组对寄存器ebx与寄存器edi的使用方法（以及其它寄存器对）。在
所有的gadget中，以下的字节序列被选中（Windows 8与Windows 10的ntdll.dll中都存在）
：
```asm
13 BC 13 BD 13 BE 13
12 17
```

以上序列与下面的汇编代码对应：
```asm
adc edi, dword ptr [ebx+edx+13BE13BDh]
adc dl, byte ptr [edi]
```
预测执行上述gadget，并由攻击者控制寄存器ebx与寄存器edi的值，可以允许攻击者读取
victim的内存。如果攻击者选择ebx = m - 0x13BE13BD - edx，其中edx = 3
（通过运行debugger得知），第一个指令从地址m读取一个32位的值k，然后把它与寄存器
edi的值相加。（在victim中，carry flag被清除，因此不需要进位）。因为寄存器edi也被
攻击者控制，预测执行的第二条指令会读取（同时缓存）特定地址（k + edi的原始值）的
一个字节。因此，攻击者可以把2³²个可能的内存值k映射到一个更小的区域，随后可以通过
Flush + Reload对这个区域进行分析。例如，如果位于m + 2，和m + 3的两个字节的值是已
知的（只需要映射m + 0，和m + 1这两个字节），寄存器edi中的值可以对冲m + 2，和
m + 3这两个字节的值，而将k映射到一个64KB（2¹⁶）的区域，这更容易通过
Flush + Reload来分析。

Sleep()函数的第一条指令是一条类似于“jmp dword ptr ds:[76AE0078h]”的跳转指令
（因为启用了ASLR，每次重启，保存跳转指令目标地址的内存地址，与跳转指令的目标地址
都会变化），这条指令被选择用于训练BTB，因为看起来攻击者进程可以clflush目标地址，
尽管（后面会解释）这不可能。此外，不同于return指令，这条指令之后没有相邻的指令可
能重新缓存返回地址（如，通过访问栈）并限制预测执行。

为了让victim预测执行gadget，需要把保存跳转指令目标地址的cache line从缓存清除，并
且BTB需要被训练将预测执行的路径导向gadget。具体步骤如下：

* 通过简单的指针操作来定位Sleep()函数入口处的跳转指令，以及保存跳转目标地址的内
  存地址。这一步在攻击者代码中执行，因为Sleep()函数在windows32.dll中；

* 在内存中扫描ntdll.dll的内容，并从中寻找gadget，此外一些共享的DLL被选择用来执行
  Flush + Reload；

* 为了准备训练BTB，包含跳转指令目标地址的那一页被设置为可写（通过copy-on-write）
  并且跳转指令目标地址被修改为gadget地址。通过相同的方法，一条“ret 4”指令被写入
  gadget所在的地址；这些修改不影响victim看到的内存（它运行在另外一个进程），但是
  当攻击者调用Sleep()函数的时候，会跳转到gadget所在的虚拟地址（这会训练BTB），然
  后立即返回；

* 启动一个独立的线程，它反复把victim中保存跳转目标地址的cache line淘汰出缓存。
  （尽管保存跳转目标地址的memory line在攻击者与victim空间中的虚拟地址是相同的，
  但是两者的物理地址不同，可能是由于之前的copy-on-write所致）。因此不能使用
  clflush，而只能用JavaScript例子中的通用方法：申请一个大数组，并通过访问一系列
  地址跨度为4,096个字节的地址来清除缓存；

* 启动多个线程训练BTB。它们使用一个2²⁰个字节（1MB）的，全部填充了“0xC3”的可执行
  内存区域（0xC3是ret指令的机器码。victim所有可能的跳转目标被映射到这个区域内的
  地址，并针对在初始训练阶段确定的ASLR基地址做调整，稍后会讨论）。这些训练线程运
  行一个循环，并在循环中反复执行以下操作：
  - 将1MB个字节的地址压入堆栈；
  - 执行ret指令，这一条ret指令从栈顶获取返回地址，从而导致一系列的ret指令被执行
    ；
  - 调用Sleep(0)，从而执行gadget；因为此时gadget的内容是"ret"，程序返回到循环；
    为了鼓励训练线程与victim运行超线程，淘汰线程与probe线程被设置运行于同一个CPU
    核心（通过设置affinity）并占用这个核心的全部资源，将其余CPU核心留给victim与
    训练进程。

  注意：对于这一步，存在以下未解决的疑问。关于这些问题论文中的叙述有些语焉不详：
  - 训练BTB只要执行Sleep(0)就可以了，为什么需要执行这些ret指令？我猜测可能希望通
    过这些操作来占用CPU资源，从而诱发超线程；
  - 1MB这个数字计算的依据是什么？我猜测可能因为BTB只使用跳转指令中低段的20位地址
    作为索引，因此1MB恰好可以覆盖所有可能的地址，这个操作可以用来Flush BTB，但是
    Flush BTB的意义何在呢？仍然不是很理解。
  - “vimtim所有可能的跳转目标 / victim's pattern of jump destinations”是什么意思
    ？
  - 训练阶段确定的ASLR基地址是如何确定的？

* 在训练的初始化阶段，当调用Sleep(0)的时候，我们通过修改文件内容来设置寄存器ebx
  与edi的值，从而保证地址ebx + 3h + 13BE13BDh]指向DLL中的某个区域，而这个区域的
  值是已知的，并且并且寄存器edi的值保证第二条操作指向另外一个容易监控的区域（应
  该也是DLL的区域）。通过以上的设置，branch predictor训练的指令序列实际上已经针
  对victim的ASLR进行了矫正（这一句不理解）。

* 最后，一旦发现有效的跳转序列，说明BTB已经训练成功，攻击者就可以通过调整寄存器
  ebx与edi的值来遍历victim的地址空间，从而并定位并读取victim的数据区
  （因为ASLR，数据区的地址会变化）。但是论文中并没有说明是否需要破解victim的ASLR
  ，而且因为前面对于ASLR矫正的叙述语焉不详，此处我也不太确定作者的观点。

#### 5.2.6.4 应对措施
本章节中我们简单分析一下针对spectre攻击的各种可能的应对措施。

##### 5.2.6.4.1 条件分支
基于条件分支的攻击可以通过在代码执行的某些敏感路径上拦截预测执行来应对。在
Intel x86体系中，可以通过串行化指令来达到这一目的。

###### 5.2.6.4.1.1 串行化指令
所谓串行化指令[[54]]，是指这样一种指令，只有所有在它之前执行的指令都已经执行完毕
，这条指令才可以被执行，从而可以保证位于这条串行化指令之后的所有指令不会被预测执
行。在Intel的x86体系中的三条串行化指令中，只有cpuid这条指令可以在普通模式中使用
，但是它会破坏很多寄存器的状态。此外，mfence与lfence指令（sfence不行）也可以达到
同样的效果，并且不会破坏寄存器的状态。

例如：
```c
if (x > size) {
   cpuid();
   // 以下代码不能预测执行，因为cpuid指令是一条串行化指令
}
```

注意：目前在Intel的技术文档中mfence与lfence指令对预测执行的影响是不明确的，因此
不能保证这两条指令对所有的CPU有效。然而，Intel的工程师已经表示在未来将明确lfence
指令对预测执行的制约效果。

###### 5.2.6.4.1.2 延迟
理论上，在条件分支中增加延迟也可以阻止预测执行。但是在发生cache miss的时候预测执
行可能比当前指令超前200条指令，并且有可能预测执行更多指令。因此，可能需要在分支
中预设很长的延迟，这会对性能造成很大影响，因此并不可行。

例如：
```c
if (x > size) {
   sleep(999999);
   // sleep()会优先被预测执行，因此它之后的指令来不及被预测执行
}
```

###### 5.2.6.4.1.3 总结
在代码中增加拦截预测执行的指令也会面临一些挑战。尽管编译器可以很轻易地在所有需要
的地方插入这类代码（在每个条件分支的后继指令处，以及分支的目标处插入），但这会严
重降低性能，静态分析技术也许可以减少一些这类检查。仅仅在与安全相关的地方插入这类
代码是不够的，因为spectre攻击仍然可以利用非关键代码来读取安全信息。此外，这种解
决方案需要重新编译代码，这对很多陈旧的软件来说是一个不小的挑战，因为很可能很多库
已经不存在了。

##### 5.2.6.4.2 间接跳转
想通过软件来应对基于间接跳转的攻击更加具有挑战性，这基本上有以下几种可能。

###### 5.2.6.4.2.1 Disabling Hyper-Threading
理论上通过禁用Hyper-Threading / 超线程，并在每次进程切换的时候清空BTB的状态，应
该可以部分化解这类攻击，虽然目前似乎并没有任何系统架构定义的方法能做到这一点。这
种方法也不能解决所有的情况，例如switch()语句中一个case的输入对另一个case而言可能
是危险的（这种情况可能发生在解释器或解析器中）。此外，在其它形式的跳转指令
（如中断处理）后的预测执行行为目前仍然未知，并且很可能随CPU的类型而变化。

注意：对于switch语句的这段叙述我不是很理解，很遗憾作者并没有提供任何例子来进一步
说明。

###### 5.2.6.4.2.2 Microcode / 微代码
可以通过微代码补丁来彻底禁用预测执行，或防止对内存进行预测读取，但是这也会带来严
重的性能问题。

###### 5.2.6.4.2.3 Buffering Speculative Effects
将预测执行初始化的内存事务在cache外缓存，直到预测执行的指令被提交，但这也不足以
解决问题，因为预测执行的时间也可以泄露信息。这一段也不是非常理解，论文中缺少具体
的例子。

###### 5.2.6.4.2.4 Retpoline
Retpoline [[8]] 是由Google创造的一种能有效解决spectre攻击的软件解决方案。
Retpoline基于这样一个事实，因为函数的调用/call与返回/ret以及与之对应的栈操作的广
泛使用，现代CPU在很大程度上对此进行了优化。简言之，当一个“call”被执行，返回地址
被压入栈内。当一个“ret”被执行，返回地址从栈顶弹出，程序从这个地址继续执行。负责
预测执行的硬件会记住这个被压入栈内的返回地址，并且在预测执行返回之后也会从这个被
记住的地址继续执行。

这样描述有点过于抽象，具体而言，retpoline通过构造一种被称为retpoline结构的代码来
替换所有的间接跳转。参照以下的例子。

原始的跳转语句：
```asm
jmp [r11]; 跳转到寄存器r11中所存储的地址
```

被以下的retpoline结构替换：
```asm
call set_up_target; (1)

capture_spec: (4)
    pause;
    jmp capture_spec;

set_up_target:
    mov [rsp], r11; (2)
    ret;            (3)
```

Retpoline的工作原理如下：

1. 直接调用``set_up_target()``，这个函数的地址是在编译时确定的，因此不需要向内存
   寻址，也就不会触发预测执行；这个函数被调用时，CPU会将返回地址
   （指向``capture_spec()``）压入栈中，同时也存入RSB（Return Stack Buffer）中。

1. 修改由(1)压入栈内的返回地址，改为寄存器r11内的地址；注意，这个操作不会修改RSB
   中保存的返回地址，RSB中的返回地址仍然指向``capture_spec()``；

1. 返回

   1. 拦截预测执行：在执行(2)的时候，因为需要等待从内存读取的地址，CPU预测执行
      (3)。而预测执行ret指令的时候，CPU从RSB，而不是栈中获得返回地址，因此预测执
      行会跳转到(4)，即``capture_spec()``，从而陷入死循环；

   1. 正常返回：当CPU最终从内存中读取到地址，CPU以正常方式执行ret指令，此时CPU从
      栈顶，而不是RSB获取返回地址。因为在(2)这一步从内存中读取的地址被写入栈顶，
      此时程序会跳转到这个地址，而这与``jmp [r11]``是等价的；

重要的是，在间接跳转到目标地址的同时，在上述执行中的任何位置，外界的攻击者都无法
控制预测执行。这种方法真是神来之笔，令人敬佩！不过这种方法的弊端就是所有的软件都
必须重新编译，从而将间接跳转换成retpoline结构。对于云服务商而言，因为他们可以控
制所有软件，重新编译并不是一个问题。然而，对于其他人而言，这并不容易，有时甚至是
不可能的。

#### 5.2.6.5 结论与未来的工作
软件隔离技术被冠以不同的名称并得到广泛应用，包括沙箱，进程分离，容器，内存安全，
proof-carrying code。所有这些实践都是基于一个基本的假设，就是CPU会忠实地执行软件
，包括软件的安全检查。不幸的是，预测执行通过允许攻击者破坏内存与寄存器内容的私密
性（而非完整性，意思是预测执行并不能修改最终结果）从而破坏了这一基本假设。这一结
果对很大一部分软件隔离解决方案造成了影响。此外，当前应对缓存攻击的措施只考虑到了
正常执行的指令，而没有考虑到预测执行的指令所产生的效果，因此也受到了影响。

这种攻击的可行性依赖于很多因素，包括victim的CPU与软件，以及攻击者与victim通讯的
能力。虽然网络攻击是可能的，目前主要的威胁仍然来自与victim运行在相同CPU上的攻击
程序。在这些本地攻击的案例中，攻击原理可以很直接了当，具体的攻击却可能依赖于一些
细节，例如victim编译器对于寄存器与内存的选择。模糊测试工具可以被攻击者利用来寻找
软件中的弱点。

因为这种攻击牵涉到了一些目前还没有被官方文档提及的硬件效应，对某一个软件的攻击可
能会随处理器的不同而有所变化。例如，一些间接跳转的测试可以在Skylake上重现，在
Hashwell处理器上却不行。AMD宣称“其Ryzen处理器具备一个AI神经网络，可以根据应用程
序过去的运行来预测未来的执行路径”，这暗示着更为复杂的预测执行行为。因此，尽管上
述的临时解决方案在短期内可以限制攻击行为，目前没有办法确切知道一段特定的代码是，
还是否，可以安全运行于目前的各种处理器上。

未来有大量的工作等待在前方。软件安全的基础依赖于软件与硬件开发者们对CPU可以从运
算中泄露什么信息这件事达成清晰的共识。因此，长期的解决方案需要更新处理器指令集来
包含清晰的关于处理器安全属性的提示，并且也需要更新CPU的硬件实现与之兼容。

更广泛地讲，安全与性能是一对矛盾。论文中提及的攻击方法，以及很多其它的方法，源于
长久以来业界对性能最大化的追求。因此，处理器，编译器，设备驱动程序，操作系统，以
及大量的其它关键部件已经在彼此复合的不同层次进化出各种复杂优化，从而引入了安全风
险。随着风险成本的升高，这些设计原则需要被重新考虑，并且在很多情况下将需要专门针
对安全的优化。

# 6. 参考文献
A                                                                                           | B
--------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------
 [1] [Meltdown & Spectre][1]                                                                |  [2] [Meltdown & Spectre - the Inner Workings][2]
 [3] [Some thoughts on Spectre and Meltdown][3]                                             |  [4] [Meltdown and Spectre, Explained][4]
 [5] [HugeTLB - Large Page Support in the Linux Kernel][5]                                  |  [6] [Sandy Bridge][6]
 [7] [L3 Cache Mapping on Sandy Bridge CPUs][7]                                             |  [8] [Retpoline: a Software Construct for Preventing Branch-Target-Injection][8]
 [9] [Anatomy of a Program in Memory][9]                                                    | [10] [A Clarification on Linux Addressing][10]
[11] [High Memory Handling][11]                                                             | [12] [`X86_64` Linux Memory Map][12]
[13] [`X86_64`][13]                                                                         | [14] [Exbibit][14]
[15] [Analysis of `__phys_addr_nodebug()`][15]                                              | [16] [Multiple Virtual Addresses Resolve to Same Physical Address][16]
[17] [Page Fault Handling][17]                                                              | [18] [How does a Higher Half Kernel Work?][18]
[19] [The Source of `page_32.h`][19]                                                        | [20] [The Source of `page_32_types.h`][20]
[21] [The Source of `page_64.h`][21]                                                        | [22] [The Source of `page_64_types.h`][22]
[23] [Last-Level Cache Side-Channel Attacks are Practical][23]                              | [24] [Adaptive Cache Replacement Policy][24]
[25] [The Linux `likwid-features` Command Line][25]                                         | [26] [Cache Basics][26]
[27] [Introduction to Hyper-Threading Technology][27]                                       | [28] [Why the Spectre and Meltdown Patches will Hurt Performance][28]
[29] [Google Project Zero - Reading Privileged Memory with a Side-Channel][29]              | [30] [A Brief History of Branch Predictor][30]
[31] [Thoughts on the AnC Attack][31]                                                       | [32] [Thoughts on the BTB Paper][32]
[33] [Anc Project][33]                                                                      | [34] [Anc Demo Code][34]
[35] [Exploit Excercises][35]                                                               | [36] [Intel 64 and IA-32 Architectures Optimization Reference Manual - PDF][36]
[37] [Access to High Memory - PPT][37]                                                      | [38] [Jump Over ASLR: Attacking Branch Predictors to Bypass ASLR - PDF][38]
[39] [ASLR on the Line: Practical Cache Attacks on the MMU - PDF][39]                       | [40] [Breaking Kernel Address Space Layout Randomization with Intel TSX - PDF][40]
[41] [Introduction to ASLR - PDF][41]                                                       | [42] [Format String Vulnerbility - PDF][42]
[43] [Meltdown - PDF][43]                                                                   | [44] [Spectre - PDF][44]
[45] [Performing a ret2libc Attack - PDF][45]                                               | [46] [Virtual Memory and Linux - PDF][46]
[47] [Undermining the Linux Kernel: Malicious Code Injection via /dev/mem - PDF][47]        | [48] [Side-Channel Attacks on Everyday Application: Distinguishing Inputs with FLUSH + RELOAD - PDF][48]
[49] [FLUSH + RELOAD: a High Resolution, Low Noise, L3 Cache Side-Channel Attack - PDF][49] | [50] [Prime + Abort: A Timer-Free High-Precision L3 Cache Attack Using Intel TSX - PDF][50]
[51] [Last-Level Cache Side-Channel Attacks are Practical - PDF][51]                        | [52] [Mapping the Intel Last-Level Cache - PDF][52]
[53] [Introduction to Memory Prefetching - PDF][53]                                         | [54] [Using the RDTSC Instruction for Performance Monitoring][54]
[55] [Introduction to Branch Predicition - PDF][55]                                         | [56] [Introduction to Evict-Time Attack - PDF][56]
[57] [Bypassing ASLR with ret2plt Attack][57]                                               | [58] [Bypassing ASLR with Bruteforcing Attack][58]
[59] [Some Pending Issues about Spectre Attack][59]                                         | [60] [A Pending Issue about Prime + Probe Attack][60]
[61] [KAISER: Kernel Address Isolation to have Side-Channels Efficiently Removed][61]       | [62] [Covert Channel][62] 
[63] [Hexadecimal][63]                                                                      | 

 [1]: https://meltdownattack.com/ "Meltdown & Spectre"
 [2]: https://steemit.com/technology/@biw/en-de-meltdown-and-spectre-the-inner-workings-part-3-spectre "Meltdown & Spectre - the Inner Workings"
 [3]: http://www.daemonology.net/blog/2018-01-17-some-thoughts-on-spectre-and-meltdown.html "Some Thoughts on Spectre and Meltdown" 
 [4]: https://medium.com/@mattklein123/meltdown-spectre-explained-6bc8634cc0c2 "Meltdown and Spectre, Explained"
 [5]: https://linuxgazette.net/155/krishnakumar.html "HugeTLB - Large Page Support in the Linux Kernel"
 [6]: https://en.wikipedia.org/wiki/Sandy_Bridge "Sandy Bridge"
 [7]: http://lackingrhoticity.blogspot.kr/2015/04/l3-cache-mapping-on-sandy-bridge-cpus.html "L3 Cache Mapping on Sandy Bridge CPUs"
 [8]: https://support.google.com/faqs/answer/7625886 "Retpoline: a Software Construct for Preventing Branch-Target-Injection"
 [9]: https://manybutfinite.com/post/anatomy-of-a-program-in-memory/ "Anatomy of a Program in Memory"
[10]: https://users.nccs.gov/~fwang2/linux/lk_addressing.txt "A Clarification on Linux Addressing"
[11]: https://www.kernel.org/doc/Documentation/vm/highmem.txt "High Memory Handling"
[12]: https://www.kernel.org/doc/Documentation/x86/x86_64/mm.txt "X86_64 Linux Memory Map"
[13]: https://en.wikipedia.org/wiki/X86-64#Virtual_address_space_details "X86_64"
[14]: https://en.wikipedia.org/wiki/Exbibit "Exbibit"
[15]: https://gist.github.com/wbs0829/094620aace1a1135a569680568f78401 "Analysis of __phys_addr_nodebug()" 
[16]: https://stackoverflow.com/questions/31396090/kernel-sys-call-table-address-does-not-match-address-specified-in-system-map "Multiple Virtual Addresses Resolve to Same Physical Address"
[17]: http://www.informit.com/articles/article.aspx?p=29961&seqNum=5 "Page Fault Handling"
[18]: https://medium.com/@connorstack/how-does-a-higher-half-kernel-work-107194e46a64 "How does a Higher Half kernel Work?"
[19]: https://github.com/torvalds/linux/blob/ead751507de86d90fa250431e9990a8b881f713c/arch/x86/include/asm/page_32.h "The Source of page_32.h"
[20]: https://github.com/torvalds/linux/blob/ead751507de86d90fa250431e9990a8b881f713c/arch/x86/include/asm/page_32_types.h#L20 "The Source of page_32_types.h"
[21]: https://github.com/torvalds/linux/blob/ead751507de86d90fa250431e9990a8b881f713c/arch/x86/include/asm/page_64.h "The Source of page_64.h"
[22]: https://github.com/torvalds/linux/blob/ead751507de86d90fa250431e9990a8b881f713c/arch/x86/include/asm/page_64_types.h "The Source of page_64_types.h"
[23]: https://www.youtube.com/watch?v=vpGI1ggKzC4 "Last-Level Cache Side-Channel Attacks are Practical" 
[24]: http://blog.stuffedcow.net/2013/01/ivb-cache-replacement/ "Adaptive Cache Replacement Policy"
[25]: https://manpages.debian.org/testing/likwid/likwid-features.1.en.html "The Linux likwid-features Command Line"
[26]: https://www.youtube.com/playlist?list=PLnsg37yOUA6mN2oqB75nwq82-MOJ3KjAO "Cache Basics"
[27]: https://software.intel.com/en-us/articles/introduction-to-hyper-threading-technology "Introduction to Hyper-Threading Technology"
[28]: https://arstechnica.com/gadgets/2018/01/heres-how-and-why-the-spectre-and-meltdown-patches-will-hurt-performance/ "Why the Spectre and Meltdown Patches will Hurt Performance"
[29]: https://googleprojectzero.blogspot.kr/2018/01/reading-privileged-memory-with-side.html "Google Project Zero - Reading Privileged Memory with a Side-Channel"
[30]: https://danluu.com/branch-prediction/ "A Brief History of Branch Predictor"
[31]: https://github.com/lattera/articles/blob/master/infosec/Exploit%20Mitigations/ASLR/2017-02-15_anc/article.md "Thoughts on the AnC Attack"
[32]: https://github.com/lattera/articles/blob/master/infosec/Exploit%20Mitigations/ASLR/2016-10-19_btb/article.md "Thoughts on the BTB Paper"
[33]: https://www.vusec.net/projects/anc/ "AnC Project"
[34]: https://github.com/vusec/revanc "Anc Demo Code"
[35]: https://exploit-exercises.com/ "Exploit Excercises"
[36]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwj275rmpv_ZAhVB4VQKHU7RDy4QFggmMAA&url=https%3A%2F%2Fwww.intel.com%2Fcontent%2Fdam%2Fwww%2Fpublic%2Fus%2Fen%2Fdocuments%2Fmanuals%2F64-ia-32-architectures-optimization-manual.pdf&usg=AOvVaw31VXvTeMSxxZ3RqBvbJhZ4 "Intel 64 and IA-32 Architectures Optimization Reference Manual - PDF"
[37]: http://slideplayer.com/slide/5177776/ "Access to High Memory - PPT"
[38]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiV6O3Yp__ZAhWmgFQKHTMnBCwQFggmMAA&url=http%3A%2F%2Fwww.cs.ucr.edu%2F~nael%2Fpubs%2Fmicro16.pdf&usg=AOvVaw0puNcu_jglDu3ACrCMTJjv "Jump Over ASLR: Attacking Branch Predictors to Bypass ASLR - PDF"
[39]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiwjrH4p__ZAhXGJJQKHcSxABMQFggmMAA&url=https%3A%2F%2Fwww.cs.vu.nl%2F~giuffrida%2Fpapers%2Fanc-ndss-2017.pdf&usg=AOvVaw2UAb_dKTycbiNHQ5bhQB4W "ASLR on the Line: Practical Cache Attacks on the MMU - PDF"
[40]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjusrugqP_ZAhWFF5QKHS7iB9gQFggmMAA&url=https%3A%2F%2Fwww.blackhat.com%2Fdocs%2Fus-16%2Fmaterials%2Fus-16-Jang-Breaking-Kernel-Address-Space-Layout-Randomization-KASLR-With-Intel-TSX.pdf&usg=AOvVaw3Zal2kaa996HtxIRYc25TM "Breaking Kernel Address Space Layout Randomization with Intel TSX - PDF" 
[41]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0ahUKEwiBptnUqP_ZAhVDJZQKHdsDD6sQFggmMAA&url=http%3A%2F%2Fsecurity.cs.rpi.edu%2Fcourses%2Fbinexp-spring2015%2Flectures%2F15%2F09_lecture.pdf&usg=AOvVaw0GPcgfSYF7LBZ3mNWaxTRZ "Introduction to ASLR - PDF"
[42]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiVnLr2qP_ZAhUMGZQKHXuwBoAQFggoMAA&url=https%3A%2F%2Fwww.coursehero.com%2Ffile%2F25148665%2FFormat-Stringpdf%2F&usg=AOvVaw0gYc5gloD988mnIe2XN4sL "Format String Vulnerbility - PDF"
[43]: https://meltdownattack.com/meltdown.pdf "Meltdown - PDF"
[44]: https://spectreattack.com/spectre.pdf "Spectre - PDF"
[45]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwi6j7Spqf_ZAhXqxlQKHYl3BCwQFggmMAA&url=http%3A%2F%2Fshellblade.net%2Fdocs%2Fret2libc.pdf&usg=AOvVaw3bUDNlN1qo6HPdwLsjIotY "Performing a ret2libc Attack - PDF"
[46]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwicgo26qf_ZAhWprVQKHbzrCSkQFggpMAE&url=https%3A%2F%2Felinux.org%2Fimages%2Fb%2Fb0%2FIntroduction_to_Memory_Management_in_Linux.pdf&usg=AOvVaw3XcwVwN75NTSud_PvT-wk6 "Virtual Memory and Linux - PDF"
[47]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwijt5Dgqf_ZAhVGHZQKHZRkBcsQFggmMAA&url=http%3A%2F%2Fwww.blackhat.com%2Fpresentations%2Fbh-europe-09%2FLineberry%2FBlackHat-Europe-2009-Lineberry-code-injection-via-dev-mem-slides.pdf&usg=AOvVaw2FfSDxzB4kT9vXudFd0p54 "Undermining the Linux Kernel: Malicious Code Injection via /dev/mem - PDF"
[48]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwj8maCFqv_ZAhUJkJQKHX1SBLkQFggsMAE&url=https%3A%2F%2Fwww.blackhat.com%2Fdocs%2Fus-16%2Fmaterials%2Fus-16-Hornby-Side-Channel-Attacks-On-Everyday-Applications-wp.pdf&usg=AOvVaw0Z0_6SQwjLHqEiN3lm2AGR "Side-Channel Attacks on Everyday Applications: Distinguishing Inputs with FLUSH + RELOAD - PDF"
[49]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwivr4Svqv_ZAhVsz1QKHRsjBywQFggmMAA&url=https%3A%2F%2Feprint.iacr.org%2F2013%2F448.pdf&usg=AOvVaw0s-7ArprdQAloj7ndiEdXS "FLUSH + RELOAD: a High Resolution, Low Noise, L3 Cache Side-Channel Attack - PDF"
[50]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiVucXIqv_ZAhWKiVQKHVY_AC0QFggmMAA&url=http%3A%2F%2Fwww.sysnet.ucsd.edu%2Fsysnet%2Fmiscpapers%2Fsec17-disselkoen.pdf&usg=AOvVaw0F3uGVLxqpOcWAWgWquNNU "Prime + Abort: A Timer-Free High-Precision L3 Cache Attack using Intel TSX - PDF"
[51]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwi70_jjqv_ZAhWp5lQKHespCi8QFggmMAA&url=http%3A%2F%2Fpalms.ee.princeton.edu%2Fsystem%2Ffiles%2FSP_vfinal.pdf&usg=AOvVaw31J2um_TWt_egUyEjahI2- "Last-Level Cache Side-Channel Attacks are Practical - PDF"
[52]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwi_2p6Hq__ZAhUCHZQKHVHVAfwQFggmMAA&url=https%3A%2F%2Feprint.iacr.org%2F2015%2F905.pdf&usg=AOvVaw38pWd4bnw-iXB88h8wRkgH "Mapping the Intel Last-Level Cache - PDF"
[53]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwib2P-Yq__ZAhUKxlQKHRCMDAEQFggqMAA&url=https%3A%2F%2Fcompas.cs.stonybrook.edu%2F~nhonarmand%2Fcourses%2Fsp16%2Fcse502%2Fslides%2F13-prefetch.pdf&usg=AOvVaw11xGBk06hm1Q1QovuD8EKc "Introduction to Memory Prefetching - PDF"
[54]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwiFooGzq__ZAhUFB3wKHXCoDDAQFggmMAA&url=https%3A%2F%2Fwww.ccsl.carleton.ca%2F~jamuir%2Frdtscpm1.pdf&usg=AOvVaw37l5DRvU_JSiDumNVfizzx "Using the RDTSC Instruction for Performance Monitoring - PDF"
[55]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwir6Mfnq__ZAhVEilQKHXwKDSkQFggmMAA&url=https%3A%2F%2Fweb.njit.edu%2F~rlopes%2FMod5.3.pdf&usg=AOvVaw3os_BmZXQEgl2PuPQHU-Y0 "Introduction to Branch Prediction - PDF" 
[56]: https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=2&cad=rja&uact=8&ved=0ahUKEwiSv-qArP_ZAhVHwlQKHa4mCtEQFggsMAE&url=http%3A%2F%2Fpalms.ee.princeton.edu%2Fsystem%2Ffiles%2F07723806.pdf&usg=AOvVaw1WPvjegxlkqbmmkKJp8bys "Introduction to Evict-Time Attack - PDF"
[57]: https://sploitfun.wordpress.com/2015/05/08/bypassing-aslr-part-i/ "Bypassing ASLR with ret2plt Attack"
[58]: https://sploitfun.wordpress.com/2015/05/08/bypassing-aslr-part-ii/ "Bypassing ASLR with Bruteforcing Attack"
[59]: https://security.stackexchange.com/questions/180981/a-question-for-the-spectre-windows-example "Some Pending Issues about Spectre Attack"
[60]: https://www.youtube.com/watch?v=vpGI1ggKzC4 "A Pending Issue about Prime + Probe Attack"
[61]: https://github.com/IAIK/KAISER "KAISER: Kernel Address Isolation to have Side-Channels Efficiently Removed"
[62]: https://security.stackexchange.com/questions/113332/covert-overt-and-side-channels "Covert Channel"
[63]: https://en.wikipedia.org/wiki/Hexadecimal "Hexadecimal"
